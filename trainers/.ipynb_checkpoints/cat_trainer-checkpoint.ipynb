{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2d87c22-4387-4aa1-9ad5-d7c515adefd2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# HOUSE PRICES TRAINER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c329355-4ccf-4ef3-88e1-b85c76e3f51b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.7\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eab36b8-9bf8-43de-9fc6-456c74b6a0bd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## DATA AND GLOBAL PARAMETERS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f58c2b-ed1f-4287-a6aa-4d83d0f0b263",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bdd4665b-d318-44ad-90e0-d2bb500f9c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIRBARIES ------\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "# Misc\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Combinatorics\n",
    "from itertools import product\n",
    "from pickle import dump\n",
    "\n",
    "# Matrices\n",
    "import numpy as np\n",
    "\n",
    "# DF\n",
    "import pandas as pd\n",
    "\n",
    "# Boosting machine\n",
    "import xgboost as xgb\n",
    "from IPython.display import Markdown as md\n",
    "from IPython.display import display as printmd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import (\n",
    "    make_scorer,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    mean_squared_log_error,\n",
    "    accuracy_score,\n",
    "    f1_score\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.svm import SVC, SVR\n",
    "\n",
    "# SKLEARN ---\n",
    "# * metrics ---\n",
    "\n",
    "# * Preprocess ---\n",
    "\n",
    "# * Imputation\n",
    "\n",
    "# * CV ---\n",
    "\n",
    "# Regression\n",
    "\n",
    "\n",
    "# utils\n",
    "base_path = \"/home/jovyan/work/TP3_TP4\"  # laptop : /home/jovyan/work/CM_ML/TP3_TP4 other tower: /home/jovyan/work/TP3_TP4\n",
    "os.chdir(base_path)\n",
    "sys.path.append(base_path)\n",
    "from utils.utils import rmsle_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae74c8f9-0436-4bd1-b8b4-9b11b9eb18b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting time and time used for files 06-02-2022_11:56:35\n"
     ]
    }
   ],
   "source": [
    "# START TIME ------\n",
    "s = datetime.now()\n",
    "# time as str\n",
    "init_time = s.strftime(\"%d-%m-%Y_%H:%M:%S\")\n",
    "print(f\"Starting time and time used for files {init_time}\")\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.5f\" % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cde833b-9037-4544-b051-8f8776264fbd",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Helper functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3eb0f29-3e7c-4ca0-b863-532b57157a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FROM DATA TO MODEL DATA -----\n",
    "def preprocess_data_as_model(data, dependent, categorical):\n",
    "    # * Divide X,y ---\n",
    "    data_subset = data.drop(dependent, axis=1)\n",
    "    y = data[dependent].values\n",
    "\n",
    "    # handle categorical variables ---\n",
    "    cols_beginning = data_subset.columns.values\n",
    "\n",
    "    all_cols = cols_beginning\n",
    "    numeric_cols = data_subset.select_dtypes([\"number\"]).columns\n",
    "    numeric_cols_index = np.in1d(all_cols, numeric_cols)\n",
    "\n",
    "    categorical_cols = data_subset.select_dtypes([\"object\"]).columns\n",
    "    categorical_cols_index = np.in1d(all_cols, categorical_cols)\n",
    "\n",
    "    # Transformations ---\n",
    "    transformations = []\n",
    "\n",
    "    if categorical:\n",
    "        pass  # todo\n",
    "    else:\n",
    "        # Training cols ---\n",
    "        data_subset = data_subset.select_dtypes([\"number\"])  # drop categorical\n",
    "        all_cols = cols_beginning[numeric_cols_index]  # only numerical cols ....\n",
    "        numeric_cols_index = (\n",
    "            data_subset.columns.values != None\n",
    "        )  # apply transformation to all columns\n",
    "    return (\n",
    "        data_subset,\n",
    "        y,\n",
    "        all_cols,\n",
    "        numeric_cols,\n",
    "        numeric_cols_index,\n",
    "        categorical_cols,\n",
    "        categorical_cols_index,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a33c6740-4817-4146-b107-44a966451313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL TRAINERS ------\n",
    "\n",
    "\n",
    "def train_mlp(data=None, best_params=None):\n",
    "    # * Init xgb instance ---\n",
    "    mlp = MLPRegressor(max_iter=3000, random_state=123, early_stopping=True)\n",
    "    # * Set best params, normally found by a previous Grid search ---\n",
    "    if best_params:\n",
    "        print(f\"Setting best parameters: {best_params}\")\n",
    "        mlp.set_params(**best_params)\n",
    "    if data:\n",
    "        # * Fit mlp: ((x_train,y_train)) ---\n",
    "        mlp.fit(X=data[0], y=data[1])\n",
    "    return mlp\n",
    "\n",
    "\n",
    "def train_svr(data=None, best_params=None):\n",
    "    # * Init xgb instance ---\n",
    "    svr = SVR()\n",
    "    # * Set best params, normally found by a previous Grid search ---\n",
    "    if best_params:\n",
    "        print(f\"Setting best parameters: {best_params}\")\n",
    "        svr.set_params(**best_params)\n",
    "    if data:\n",
    "        # * Fit svr: ((x_train,y_train)) ---\n",
    "        svr.fit(X=data[0], y=data[1])\n",
    "    return svr\n",
    "\n",
    "\n",
    "def train_rf(data=None, best_params=None):\n",
    "    # * Init xgb instance ---\n",
    "    rf = RandomForestRegressor()\n",
    "\n",
    "    # * Set best params, normally found by a previous Grid search ---\n",
    "    if best_params:\n",
    "        print(f\"Setting best parameters: {best_params}\")\n",
    "        rf.set_params(**best_params)\n",
    "    if data:\n",
    "        # * Fit rf: ((x_train,y_train)) ---\n",
    "        rf.fit(X=data[0], y=data[1])\n",
    "    return rf\n",
    "\n",
    "\n",
    "def train_xgb(params, data=None, best_params=None):\n",
    "    # * Init xgb instance ---\n",
    "    boost = xgb.XGBRegressor(**params)\n",
    "\n",
    "    # * Set best params, normally found by a previous Grid search ---\n",
    "    if best_params:\n",
    "        print(f\"Setting best parameters: {best_params}\")\n",
    "        boost.set_params(**best_params)\n",
    "\n",
    "    # * Fit booster: ((x_train,y_train), (x_test,y_test)) ---\n",
    "    if data:\n",
    "        boost.fit(\n",
    "            X=data[0][0],\n",
    "            y=data[0][1],\n",
    "            eval_set=data,  # Validation set for early stopping (validates on test -- last data tuple)\n",
    "            early_stopping_rounds=10,\n",
    "            verbose=0,\n",
    "            eval_metric=[\"mae\", \"rmse\", \"rmsle\"],\n",
    "        )\n",
    "    return boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03037fe-8168-449f-815f-80a0a0595d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp_classification(data=None, best_params=None):\n",
    "    # * Init xgb instance ---\n",
    "    mlp = MLPClassifier(max_iter=3000, random_state=123, early_stopping=True)\n",
    "    # * Set best params, normally found by a previous Grid search ---\n",
    "    if best_params:\n",
    "        print(f\"Setting best parameters: {best_params}\")\n",
    "        mlp.set_params(**best_params)\n",
    "    if data:\n",
    "        # * Fit mlp: ((x_train,y_train)) ---\n",
    "        mlp.fit(X=data[0], y=data[1])\n",
    "    return mlp\n",
    "\n",
    "\n",
    "def train_svr_classification(data=None, best_params=None):\n",
    "    # * Init xgb instance ---\n",
    "    svr = SVC()\n",
    "    # * Set best params, normally found by a previous Grid search ---\n",
    "    if best_params:\n",
    "        print(f\"Setting best parameters: {best_params}\")\n",
    "        svr.set_params(**best_params)\n",
    "    if data:\n",
    "        # * Fit svr: ((x_train,y_train)) ---\n",
    "        svr.fit(X=data[0], y=data[1])\n",
    "    return svr\n",
    "\n",
    "\n",
    "def train_rf_classification(data=None, best_params=None):\n",
    "    # * Init xgb instance ---\n",
    "    rf = RandomForestClassifier(random_state=123)\n",
    "\n",
    "    # * Set best params, normally found by a previous Grid search ---\n",
    "    if best_params:\n",
    "        print(f\"Setting best parameters: {best_params}\")\n",
    "        rf.set_params(**best_params)\n",
    "    if data:\n",
    "        # * Fit rf: ((x_train,y_train)) ---\n",
    "        rf.fit(X=data[0], y=data[1])\n",
    "    return rf\n",
    "\n",
    "\n",
    "def train_xgb_classification(params, data=None, best_params=None):\n",
    "    # * Init xgb instance ---\n",
    "    boost = xgb.XGBClassifier(use_label_encoder=False,**params)\n",
    "\n",
    "    # * Set best params, normally found by a previous Grid search ---\n",
    "    if best_params:\n",
    "        print(f\"Setting best parameters: {best_params}\")\n",
    "        boost.set_params(**best_params)\n",
    "\n",
    "    # * Fit booster: ((x_train,y_train), (x_test,y_test)) ---\n",
    "    if data:\n",
    "        boost.fit(\n",
    "            X=data[0][0],\n",
    "            y=data[0][1],\n",
    "            eval_set=data,  # Validation set for early stopping (validates on test -- last data tuple)\n",
    "            early_stopping_rounds=10,\n",
    "            verbose=0,\n",
    "            eval_metric=[\"mae\", \"rmse\", \"rmsle\"],\n",
    "        )\n",
    "    return boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8997e70-1f93-4f22-8b3b-37667252e789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL SAVERS ------\n",
    "def save_model(\n",
    "    model,\n",
    "    model_name,\n",
    "    dataset,\n",
    "    kind,\n",
    "    objective,\n",
    "    toScale,\n",
    "    best_score,\n",
    "    init_time,\n",
    "    columns_used,\n",
    "    Preprocess,\n",
    "    preprocessing_path,\n",
    "    categorical,\n",
    "    scores,\n",
    ") -> str:\n",
    "    print(\"\\n\")\n",
    "    print(\"--- Saving model ---\")\n",
    "    model_path = f\"model_dump/{model_name}_{dataset}_{kind}_{objective}_{toScale}_{np.round(best_score,5)}_{init_time}.pkl\"\n",
    "\n",
    "    dump(\n",
    "        {  # options\n",
    "            \"scaled\": toScale,\n",
    "            \"categorical\": categorical,\n",
    "            # processing and model\n",
    "            \"columns_used\": columns_used,\n",
    "            \"preprocess\": Preprocess,\n",
    "            \"model\": model,\n",
    "            \"preprocessing_path\": preprocessing_path,\n",
    "            # outcome\n",
    "            \"scores\": scores,\n",
    "        },\n",
    "        open(model_path, \"wb\"),\n",
    "    )\n",
    "\n",
    "    print(f\"--- {model_name} model saved to {model_path}---\")\n",
    "    return model_path\n",
    "\n",
    "\n",
    "def save_grid(\n",
    "    model_path,\n",
    "    model_name,\n",
    "    dataset,\n",
    "    init_time,\n",
    "    preprocessing_path,\n",
    "    toScale,\n",
    "    categorical,\n",
    "    search,\n",
    "):\n",
    "\n",
    "    res = pd.DataFrame(search.cv_results_)\n",
    "\n",
    "    # * Save estimator ---\n",
    "    res[\"model_path\"] = model_path\n",
    "\n",
    "    # * Did we scale ?\n",
    "    if preprocessing_path:\n",
    "        res[\"preprocessing_path\"] = preprocessing_path\n",
    "    else:\n",
    "        res[\"preprocessing_path\"] = \"no preprocess\"\n",
    "\n",
    "    res[\"categorical\"] = categorical\n",
    "\n",
    "    # * To csv ---\n",
    "    grid_name = f\"grid_search/Grid_{model_name}_{dataset}_{init_time}.csv\"\n",
    "    res.to_csv(grid_name)\n",
    "    print(f\"--- Grid search results saved to {grid_name}---\")\n",
    "\n",
    "\n",
    "def score_model(model, data):\n",
    "    \"\"\"\n",
    "    data = ((xtrain, ytrain), (x_val, y_val), (x_test, y_test))\n",
    "    \"\"\"\n",
    "    splits = [\"train\", \"val\", \"test\"]\n",
    "    scores = {}\n",
    "    for i, split in enumerate(splits):\n",
    "        metrics = {}\n",
    "        metrics[\"accuracy\"] = accuracy_score(model.predict(data[i][0]), data[i][1])\n",
    "        metrics[\"f1\"] = f1_score(model.predict(data[i][0]), data[i][1])\n",
    "        scores[split] = metrics\n",
    "    return scores\n",
    "\n",
    "\n",
    "def scores_to_df(scores, verbose=True):\n",
    "    scores_df = pd.DataFrame(scores)\n",
    "    scores_df[\"difference\"] = scores_df[\"train\"] - scores_df[\"val\"]\n",
    "    if verbose:\n",
    "        print(\"---- BEST SCORES ---\")\n",
    "        print(scores_df)\n",
    "    return scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b4b7ec-a38c-4d21-aa0c-0612e45a5c82",
   "metadata": {
    "tags": []
   },
   "source": [
    "### FITTERS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fd0f2d3-111f-427a-aa53-3331fc52e078",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(model, data):\n",
    "    # PRINT BEST RESULTS ------\n",
    "    scores = score_model(model, data)\n",
    "    scores_df = scores_to_df(scores)\n",
    "\n",
    "    best_params = model.get_params()\n",
    "    printmd(md(f\"Paramètres du modèle: {best_params}\"))\n",
    "    return scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b3725046-58c1-4ca2-90c9-1be796b02bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_baseline_model(trainer, data, pass_val=False, params=False, **kwargs):\n",
    "    # --- --- --- BASELINE --- --- ---\n",
    "    kind = \"baseline\"\n",
    "\n",
    "    # * Fit if requested ---\n",
    "    if pass_val and params:\n",
    "        model = trainer(params, data, best_params=None)\n",
    "    else:\n",
    "        model = trainer((data[0][0], data[0][1]), best_params=None)\n",
    "\n",
    "    # Best rmsle ---\n",
    "    best_score = rmsle(estimator=model, X=data[1][0], y_true=data[1][1])\n",
    "\n",
    "    return (model, kind, best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7193dc1-5e9c-4890-a2fb-550048092ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_grid_model(\n",
    "    trainer,\n",
    "    data,\n",
    "    grid_params,\n",
    "    grid_search_kwargs,\n",
    "    pass_val=False,\n",
    "    params=False,\n",
    "    verbose=True,\n",
    "):\n",
    "    # --- --- --- BASELINE --- --- ---\n",
    "    kind = \"grid\"\n",
    "\n",
    "    if params:\n",
    "        # * Init instance ---\n",
    "        model = trainer(params=params)\n",
    "    else:\n",
    "        model = trainer()\n",
    "\n",
    "    # * GridSearchCV ---\n",
    "    search = GridSearchCV(model, param_grid=grid_params, **grid_search_kwargs)\n",
    "\n",
    "    # * Fit if requested ---\n",
    "    if pass_val:\n",
    "        search.fit(\n",
    "            data[0][0],\n",
    "            data[0][1],\n",
    "            eval_set=[data[1]],  # Validation set for early stopping\n",
    "            early_stopping_rounds=15,\n",
    "            verbose=0,\n",
    "        )\n",
    "    else:\n",
    "        search.fit(data[0][0], data[0][1])\n",
    "\n",
    "    # PRINT BEST RESULTS ------\n",
    "    if verbose:\n",
    "        best_score = search.best_score_\n",
    "        printmd(\n",
    "            md(\n",
    "                f\"Le meilleur score obtenu par notre grid search (à savoir, le score est le RMSLE): {best_score}\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        best_params = search.best_params_\n",
    "        printmd(md(f\"Le meilleurs paramètres: {best_params}\"))\n",
    "\n",
    "    return search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99a13e88-d427-4cd6-b689-3d9eedbcc3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refit_with_params(trainer, best_params, data, pass_val=False):\n",
    "    # * Fit if requested ---\n",
    "    if pass_val and params:\n",
    "        model = trainer(params, data, best_params=best_params)\n",
    "    else:\n",
    "        model = trainer((data[0][0], data[0][1]), best_params=best_params)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0014db5-9140-43bf-824b-3023a0aa4f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refit_with_selection(\n",
    "    trainer,\n",
    "    data,\n",
    "    model_with_importances,\n",
    "    all_cols,\n",
    "    grid_params,\n",
    "    grid_search_kwargs,\n",
    "    pass_val,\n",
    "    params,\n",
    "    best_params,\n",
    "    th=0.001,\n",
    "    verbose=False,\n",
    "):\n",
    "    # which features ---\n",
    "    subset = model_with_importances.feature_importances_ > th\n",
    "    important_cols = all_cols[subset].tolist()\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"IMPORTANT COLUMNS KEPT FOR RETRAINING {important_cols}\")\n",
    "\n",
    "    data_th = [(data[0][0][:, subset], data[0][1]), (data[1][0][:, subset], data[1][1])]\n",
    "    search = fit_grid_model(\n",
    "        trainer, data_th, grid_params, grid_search_kwargs, pass_val, params, verbose\n",
    "    )\n",
    "\n",
    "    model = refit_with_params(\n",
    "        trainer, search.best_params_, data=data_th, pass_val=pass_val\n",
    "    )\n",
    "\n",
    "    best_score = search.best_score_\n",
    "    return model, important_cols, subset, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebb1be4-f292-49ad-87e6-6860926cc874",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data Paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6b54d143-6978-426a-bc89-6b54855a3959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- --- --- FOLDERS AND FILES --- --- ---\n",
    "# * Data path ---\n",
    "data_path = os.path.join(base_path, \"data\")\n",
    "\n",
    "# * House dataset paths ---\n",
    "house_train = os.path.join(data_path, \"house\", \"train.csv\")\n",
    "\n",
    "# * Bills dataset paths ---\n",
    "bill_train = os.path.join(data_path, \"bills\",\"bill_authentication.csv\")\n",
    "\n",
    "# * Wine dataset paths ---\n",
    "wine_train = os.path.join(data_path, \"wine\",\"winequality-red.csv\")\n",
    "\n",
    "# init scaler\n",
    "scaler_name = None\n",
    "Preprocess = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89367d19-0135-47d5-95cc-c3421fc8c756",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# --- --- --- MODEL FITTING PARAMETERS --- --- ---\n",
    "\n",
    "# FIT OR LOAD MODEL ------\n",
    "toFitXGB = True\n",
    "toFitRF = True\n",
    "toFitSVM = True\n",
    "toFitMLP = True\n",
    "\n",
    "# * Fitting options ---\n",
    "toScale = True\n",
    "\n",
    "# *Handle categorical vars\n",
    "categorical = True\n",
    "\n",
    "# DEFAULT STORAGE PARAMETERS ------\n",
    "to_rm_storage = True\n",
    "### DATA PARAMETERS ---\n",
    "training_data_path = None\n",
    "dataset = None\n",
    "dependent = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08150bd-62a2-4d80-b7ca-a8fc033670ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Folders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fb1da5e-e78e-49b4-817d-baff9ff2516d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Removing previous saved models, grids and scalers ---\n",
      "CPU times: user 1.9 ms, sys: 0 ns, total: 1.9 ms\n",
      "Wall time: 3.06 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# FOLDERS TO STORE ------\n",
    "paths_to_create = [\n",
    "    os.path.join(base_path, \"scale_dump\"),\n",
    "    os.path.join(base_path, \"model_dump\"),\n",
    "    os.path.join(base_path, \"grid_search\"),\n",
    "]\n",
    "\n",
    "# REMOVE PREVIOUS STORAGE IF NEEDED ------\n",
    "if to_rm_storage:\n",
    "    print(\"--- Removing previous saved models, grids and scalers ---\")\n",
    "    for folder in paths_to_create:\n",
    "        shutil.rmtree(folder, ignore_errors=True)\n",
    "\n",
    "# (RE)CREATE STORAGE FOLDERS ------\n",
    "for folder in paths_to_create:\n",
    "    os.makedirs(folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7a80e7-c61c-4a9e-8b64-61e04f23457b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MODEL PARAMETERS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4888bc90-804c-4e00-b3e8-466dc5deff71",
   "metadata": {
    "tags": []
   },
   "source": [
    "### MODEL PARAMETERS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ac1206c0-cd17-41cd-b76e-339f1698abe2",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "265249ef-80a6-4525-9773-1595ddf85459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPUS DETECTED : 8\n",
      "CPUS TO USE : 4\n"
     ]
    }
   ],
   "source": [
    "# Multiprocessing ---\n",
    "cpus = multiprocessing.cpu_count()\n",
    "cpu_ratio = 0.8\n",
    "cpus_to_use = int(cpus * cpu_ratio)\n",
    "print(f\"CPUS DETECTED : {cpus}\")\n",
    "print(f\"CPUS TO USE : {cpus_to_use}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c93f4c-c461-4387-abfb-9062fe687a3b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### CV PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5d36cee3-2623-4300-8b83-9520ff00fb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- --- --- CV PARAMS --- --- ---\n",
    "folds = 3\n",
    "rstate = 123\n",
    "\n",
    "# * K Fold ---\n",
    "skf = KFold(n_splits=folds, shuffle=True, random_state=rstate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "77fa33b4-9378-4a0c-9b00-b5277aa25d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- --- --- XGB HYPER PARAMS --- --- ---\n",
    "# * Grid for xgb ---\n",
    "xgb_params = {\n",
    "    \"min_child_weight\": [1, 5, 10],\n",
    "    \"gamma\": [0.001, 0.02, 0.04, 0.08, 0.1, 0.5],\n",
    "    \"subsample\": [0.6, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "    \"max_depth\": [1, 2, 4, 5],\n",
    "    \"lambda\": [0, 0.01, 0.02, 0.5, 1],  # no much pbs of overfting\n",
    "}\n",
    "objective = \"reg:squaredlogerror\"  # metric RMSLE\n",
    "objective = \"reg:squarederror\"  # RMSLE STUCKED ...\n",
    "metric = \"mae\"\n",
    "rmsle = rmsle_scorer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "41b98e16-0c9a-4fae-9eab-2eb1281c43ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Original Number of combinations : 5474\n",
      "RF Number of correct combinations : 912\n"
     ]
    }
   ],
   "source": [
    "# --- --- --- RANDOM FOREST HYPER PARAMS --- --- ---\n",
    "max_depth_val = 18\n",
    "max_depth = np.arange(1, max_depth_val, 1)\n",
    "max_leaf_nodes = np.arange(\n",
    "    2, max_depth_val * max_depth_val, 1\n",
    ")  # si on ajoute un max_depth x il faut au plus accepter x*x feuilles...\n",
    "\n",
    "params_combinations = list(product(max_depth, max_leaf_nodes))\n",
    "print(\"RF Original Number of combinations : %s\" % len(params_combinations))\n",
    "\n",
    "# REMOVE ILOGIC COMBINATIONS cf.TP2 ------\n",
    "correct_params = []\n",
    "incorrect_params = []\n",
    "for depth, leaves in params_combinations:\n",
    "    max_feuilles = depth * depth\n",
    "    if leaves > max_feuilles or leaves < np.round(0.5 * max_feuilles):  # critères\n",
    "        incorrect_params.append((depth, leaves))\n",
    "    else:\n",
    "        correct_params.append((depth, leaves))\n",
    "\n",
    "rf_params = []\n",
    "for depth, leaves in correct_params:\n",
    "    grille = {\n",
    "        \"max_depth\": [depth],  # wrap in one list element\n",
    "        \"max_leaf_nodes\": [leaves],\n",
    "    }\n",
    "    rf_params.append(grille)\n",
    "\n",
    "print(\"RF Number of correct combinations : %s\" % len(correct_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee02bc68-6f18-4bca-8eee-62c2a2debd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- --- --- SVM HYPER PARAMS --- --- ---\n",
    "\n",
    "# possibilities ---\n",
    "Cs = np.linspace(0.5, 40, 7)\n",
    "KERNELS = [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]\n",
    "# grid ---\n",
    "svm_params = {\"C\": Cs, \"kernel\": KERNELS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bd1466d7-326b-453a-8e2d-54d7e32545ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- --- --- MLP HYPER PARAMS --- --- ---\n",
    "\n",
    "mlp_params = {\n",
    "    \"hidden_layer_sizes\": [(50, 50, 50), (50, 100, 50), (100,)],\n",
    "    \"activation\": [\"tanh\", \"relu\"],\n",
    "    \"solver\": [\"sgd\", \"adam\"],\n",
    "    \"alpha\": [0.0001, 0.05],\n",
    "    \"learning_rate\": [\"constant\", \"adaptive\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc8463b-ca71-45ac-a2e7-3df3ae727757",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## IMPORT DATA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f915346b-977c-433d-8ab2-a5a234fd3555",
   "metadata": {
    "tags": []
   },
   "source": [
    "### House "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "9efbacad-e9ef-4dbd-97e9-a357ee536079",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Column Transformation. Scaling:True , OneHotEncoder : True  ---\n",
      "CPU times: user 69.7 ms, sys: 40 ms, total: 110 ms\n",
      "Wall time: 742 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# --- --- --- DATA --- --- ---\n",
    "# * Load data ---\n",
    "data = pd.read_csv(eval(training_data_path), sep=\",\")\n",
    "\n",
    "(\n",
    "    data_subset,\n",
    "    y,\n",
    "    all_cols,\n",
    "    numeric_cols,\n",
    "    numeric_cols_index,\n",
    "    categorical_cols,\n",
    "    categorical_cols_index,\n",
    ") = preprocess_data_as_model(data, dependent, categorical)\n",
    "cols_beginning = data_subset.columns.values\n",
    "\n",
    "# DEFINE TRANSFORMATION BASED ON OPTIONS ------\n",
    "# Transformations ---\n",
    "transformations = []\n",
    "if categorical:\n",
    "    # One hot encoder ---\n",
    "    encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "    transformer = (\"cat_cols\", encoder, categorical_cols_index)  # on cat cols\n",
    "    transformations.append(transformer)\n",
    "\n",
    "else:\n",
    "    # Training cols ---\n",
    "    data_subset = data_subset.select_dtypes([\"number\"])  # drop categorical\n",
    "    all_cols = cols_beginning[numeric_cols_index]  # only numerical cols ....\n",
    "    numeric_cols_index = (\n",
    "        data_subset.columns.values != None\n",
    "    )  # apply transformation to all columns\n",
    "\n",
    "\n",
    "# * Optional Scaling ---\n",
    "if toScale:\n",
    "    # unit variance scaler ---\n",
    "    scaler = StandardScaler()\n",
    "    transformer = (\"num_cols\", scaler, numeric_cols_index)  # on num cols\n",
    "    transformations.append(transformer)\n",
    "\n",
    "# * TRAIN VAL TEST SPLIT ---\n",
    "# train test\n",
    "X_train, XHold_test, y_train, yHold_test = train_test_split(\n",
    "    data_subset.values, y, test_size=0.15, random_state=rstate\n",
    ")\n",
    "# train validation\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(\n",
    "    X_train, y_train, test_size=0.15, random_state=rstate\n",
    ")\n",
    "\n",
    "#\n",
    "\n",
    "if toScale or categorical:\n",
    "    print(\n",
    "        f\"--- Column Transformation. Scaling:{toScale} , OneHotEncoder : {categorical}  ---\"\n",
    "    )\n",
    "    Preprocess = ColumnTransformer(\n",
    "        transformations, n_jobs=cpus_to_use, remainder=\"passthrough\"\n",
    "    )\n",
    "    # fit ---\n",
    "    X_train = Preprocess.fit_transform(X_train)\n",
    "    X_validation = Preprocess.transform(X_validation)\n",
    "    XHold_test = Preprocess.transform(XHold_test)\n",
    "\n",
    "    # get names ---\n",
    "    all_cols = Preprocess.get_feature_names_out()\n",
    "\n",
    "    # dump to reuse\n",
    "    scaler_name = f\"scale_dump/ColumnTransformer_{dataset}_{init_time}.pkl\"\n",
    "    dump(Preprocess, open(scaler_name, \"wb\"))\n",
    "\n",
    "# TRAIN VAL TEST SPLIT ------\n",
    "data_splits = [\n",
    "    (X_train, y_train),\n",
    "    (X_validation, y_validation),\n",
    "    (XHold_test, yHold_test),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be860d2a-1571-4c8f-b5a9-2bd5e978e33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_kwargs = dict(\n",
    "    scoring=rmsle, n_jobs=cpus_to_use, refit=True, cv=skf, verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed03a8c9-7c6d-4674-a2bd-4be6f7317e27",
   "metadata": {
    "tags": []
   },
   "source": [
    "## XGBOOST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b31cdf5c-e1e8-4709-98c5-7d96bd7f8a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "saver_params = dict(\n",
    "    dataset=dataset,\n",
    "    model_name=\"xgb\",\n",
    "    objective=objective,\n",
    "    toScale=toScale,\n",
    "    init_time=init_time,\n",
    "    columns_used=all_cols,\n",
    "    Preprocess=Preprocess,\n",
    "    preprocessing_path=scaler_name,\n",
    "    categorical=categorical,\n",
    ")\n",
    "\n",
    "saver_grid_params = {}\n",
    "for i in [\n",
    "    \"model_name\",\n",
    "    \"dataset\",\n",
    "    \"init_time\",\n",
    "    \"preprocessing_path\",\n",
    "    \"toScale\",\n",
    "    \"categorical\",\n",
    "]:\n",
    "    saver_grid_params[i] = saver_params.get(i)\n",
    "\n",
    "params = {\n",
    "    \"objective\": objective,\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"n_estimators\": 700,\n",
    "    \"n_jobs\": 1,  # if not defaults to -1...\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faa5f84-83b9-4c90-892c-f10422123b66",
   "metadata": {
    "tags": []
   },
   "source": [
    "### BASIC MODEL (NO HPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "501cb85c-62ca-4c35-a8f1-a931c38caa35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- BEST SCORES ---\n",
      "               train             val       difference\n",
      "rmsle       -0.00141        -0.01715          0.01574\n",
      "rmse  26962071.28822 680274108.03494 -653312036.74672\n",
      "mae       3835.20401     16359.16402     -12523.96001\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Paramètres du modèle: {'objective': 'reg:squarederror', 'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 1, 'enable_categorical': False, 'gamma': 0, 'gpu_id': -1, 'importance_type': None, 'interaction_constraints': '', 'learning_rate': 0.02, 'max_delta_step': 0, 'max_depth': 6, 'min_child_weight': 1, 'missing': nan, 'monotone_constraints': '()', 'n_estimators': 700, 'n_jobs': 1, 'num_parallel_tree': 1, 'predictor': 'auto', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'subsample': 1, 'tree_method': 'exact', 'validate_parameters': 1, 'verbosity': None}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Saving model ---\n",
      "--- xgb model saved to model_dump/xgb_house_baseline_reg:squarederror_True_-0.01715_04-02-2022_20:19:07.pkl---\n",
      "CPU times: user 9.9 s, sys: 7.99 ms, total: 9.9 s\n",
      "Wall time: 9.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# --- --- --- XGBOOST --- --- ---\n",
    "if toFitXGB:\n",
    "    model, kind, best_score = fit_baseline_model(\n",
    "        train_xgb_classification,\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        pass_val=True,\n",
    "        params=params,\n",
    "    )\n",
    "\n",
    "    scores_df = get_results(model, data_splits)\n",
    "    # SAVE RESULTS ------\n",
    "    save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )\n",
    "    # boost.get_booster().feature_names= important_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729e4e95-b6e4-4fd5-89e0-f7d05ca2450f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "37755148-2fa9-464f-a20d-6c209325bef5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Le meilleur score obtenu par notre grid search (à savoir, le score est le RMSLE): -0.020333612485709807"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Le meilleurs paramètres: {'min_child_weight': 5}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting best parameters: {'objective': 'reg:squarederror', 'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 1, 'gamma': 0, 'gpu_id': -1, 'interaction_constraints': '', 'learning_rate': 0.02, 'max_delta_step': 0, 'max_depth': 6, 'min_child_weight': 5, 'monotone_constraints': '()', 'n_jobs': 1, 'num_parallel_tree': 1, 'predictor': 'auto', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'subsample': 1, 'tree_method': 'exact', 'validate_parameters': 1, 'verbosity': None}\n",
      "---- BEST SCORES ---\n",
      "               train             val       difference\n",
      "rmsle       -0.00220        -0.01664          0.01444\n",
      "rmse  45670448.67491 682049727.05744 -636379278.38254\n",
      "mae       4948.55395     15708.35536     -10759.80142\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Paramètres du modèle: {'objective': 'reg:squarederror', 'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 1, 'enable_categorical': False, 'gamma': 0, 'gpu_id': -1, 'importance_type': None, 'interaction_constraints': '', 'learning_rate': 0.02, 'max_delta_step': 0, 'max_depth': 6, 'min_child_weight': 5, 'missing': nan, 'monotone_constraints': '()', 'n_estimators': 700, 'n_jobs': 1, 'num_parallel_tree': 1, 'predictor': 'auto', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'subsample': 1, 'tree_method': 'exact', 'validate_parameters': 1, 'verbosity': None}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Saving model ---\n",
      "--- xgb model saved to model_dump/xgb_house_grid_reg:squarederror_True_-0.01715_04-02-2022_20:19:07.pkl---\n",
      "--- Grid search results saved to grid_search/Grid_xgb_house_04-02-2022_20:19:07.csv---\n",
      "CPU times: user 24.4 s, sys: 16 ms, total: 24.4 s\n",
      "Wall time: 49 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# --- --- --- XGBOOST GRID SEARCH --- --- ---\n",
    "if toFitXGB:\n",
    "    kind = \"grid\"\n",
    "\n",
    "    search = fit_grid_model(\n",
    "        train_xgb_classification,\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        grid_params=xgb_params,\n",
    "        grid_search_kwargs=grid_search_kwargs,\n",
    "        pass_val=True,\n",
    "        params=params,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # REFIT TO GET TRAINING ERROR AT EACH STEP ------\n",
    "\n",
    "    model = refit_with_params(\n",
    "        train_xgb_classification,\n",
    "        search.best_estimator_.get_xgb_params(),\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        pass_val=True,\n",
    "    )\n",
    "    # Score model ---\n",
    "    scores_df = get_results(model, data_splits)\n",
    "    best_score = search.best_score_\n",
    "    # Save model ---\n",
    "    model_path = save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )\n",
    "    # Save grid search results ---\n",
    "    save_grid(model_path=model_path, search=search, **saver_grid_params)\n",
    "    # boost.get_booster().feature_names= important_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c0b82c-7cb2-4898-baab-f916b1766e6d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Refit on feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c9486b96-a180-47ca-8e50-54bfae922f10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Setting best parameters: {'objective': 'reg:squarederror', 'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 1, 'gamma': 0, 'gpu_id': -1, 'interaction_constraints': '', 'learning_rate': 0.02, 'max_delta_step': 0, 'max_depth': 6, 'min_child_weight': 5, 'monotone_constraints': '()', 'n_jobs': 1, 'num_parallel_tree': 1, 'predictor': 'auto', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'subsample': 1, 'tree_method': 'exact', 'validate_parameters': 1, 'verbosity': None}\n",
      "---- BEST SCORES ---\n",
      "               train             val       difference\n",
      "rmsle       -0.00220        -0.01664          0.01444\n",
      "rmse  45670448.67491 682049727.05744 -636379278.38254\n",
      "mae       4948.55395     15708.35536     -10759.80142\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Paramètres du modèle: {'objective': 'reg:squarederror', 'base_score': 0.5, 'booster': 'gbtree', 'colsample_bylevel': 1, 'colsample_bynode': 1, 'colsample_bytree': 1, 'enable_categorical': False, 'gamma': 0, 'gpu_id': -1, 'importance_type': None, 'interaction_constraints': '', 'learning_rate': 0.02, 'max_delta_step': 0, 'max_depth': 6, 'min_child_weight': 5, 'missing': nan, 'monotone_constraints': '()', 'n_estimators': 700, 'n_jobs': 1, 'num_parallel_tree': 1, 'predictor': 'auto', 'random_state': 0, 'reg_alpha': 0, 'reg_lambda': 1, 'scale_pos_weight': 1, 'subsample': 1, 'tree_method': 'exact', 'validate_parameters': 1, 'verbosity': None}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Saving model ---\n",
      "--- xgb model saved to model_dump/xgb_house_grid_reg:squarederror_True_-0.01715_04-02-2022_20:19:07.pkl---\n",
      "--- Grid search results saved to grid_search/Grid_xgb_house_04-02-2022_20:19:07.csv---\n"
     ]
    }
   ],
   "source": [
    "if toFitXGB:\n",
    "    model, important_cols, subset, best_score = refit_with_selection(\n",
    "        train_xgb_classification,\n",
    "        [(X_train, y_train), (X_validation, y_validation)],\n",
    "        model_with_importances=model,\n",
    "        all_cols=all_cols,\n",
    "        grid_params=xgb_params,\n",
    "        grid_search_kwargs=grid_search_kwargs,\n",
    "        pass_val=True,\n",
    "        params=params,\n",
    "        best_params=search.best_estimator_.get_xgb_params(),\n",
    "        th=0.001,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    model.get_booster().feature_names = important_cols\n",
    "\n",
    "    data_splits_th = [\n",
    "        (data_splits[0][0][:, subset], data_splits[0][1]),\n",
    "        (data_splits[1][0][:, subset], data_splits[1][1]),\n",
    "        (data_splits[2][0][:, subset], data_splits[2][1]),\n",
    "    ]\n",
    "\n",
    "    scores_df = get_results(model, data_splits_th)\n",
    "    # Save model ---\n",
    "    kind = \"refit\"\n",
    "    model_path = save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92dc3d7-6238-447e-81e5-44d0863987f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## RF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3c4c47ec-7d1d-40be-ba9d-00db2bf58dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Column Transformation. Scaling:True , OneHotEncoder : True, Imputer : knnImputer  ---\n"
     ]
    }
   ],
   "source": [
    "# * Split for learning ---\n",
    "# train test\n",
    "if toFitRF or toFitMLP or toFitSVM:\n",
    "\n",
    "    X_train, XHold_test, y_train, yHold_test = train_test_split(\n",
    "        data_subset.values, y, test_size=0.15, random_state=rstate\n",
    "    )\n",
    "    # train validation\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(\n",
    "        X_train, y_train, test_size=0.15, random_state=rstate\n",
    "    )\n",
    "\n",
    "    knnI = KNNImputer()\n",
    "    #\n",
    "    if toScale or categorical:\n",
    "        print(\n",
    "            f\"--- Column Transformation. Scaling:{toScale} , OneHotEncoder : {categorical}, Imputer : knnImputer  ---\"\n",
    "        )\n",
    "        Preprocess = ColumnTransformer(\n",
    "            transformations, n_jobs=cpus_to_use, remainder=\"passthrough\"\n",
    "        )\n",
    "\n",
    "        Preprocess = Pipeline([(\"col_trans\", Preprocess), (\"imputer\", knnI)])\n",
    "    else:\n",
    "        Preprocess = Pipeline([(\"imputer\", knnI)])\n",
    "\n",
    "    # fit ---\n",
    "    Preprocess.fit(X_train)\n",
    "    X_train = Preprocess.transform(X_train)\n",
    "    X_validation = Preprocess.transform(X_validation)\n",
    "    XHold_test = Preprocess.transform(XHold_test)\n",
    "\n",
    "    # get names ---\n",
    "    if toScale or categorical:\n",
    "\n",
    "        all_cols = Preprocess[0].get_feature_names_out()\n",
    "\n",
    "    # dump to reuse\n",
    "    preprocessing_name = f\"scale_dump/ColumnTransformer__rf_{init_time}.pkl\"\n",
    "    dump(Preprocess, open(preprocessing_name, \"wb\"))\n",
    "\n",
    "# TRAIN VAL TEST SPLIT ------\n",
    "data_splits = [\n",
    "    (X_train, y_train),\n",
    "    (X_validation, y_validation),\n",
    "    (XHold_test, yHold_test),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a48298-3ca5-4168-bc0a-d9fceda01119",
   "metadata": {
    "tags": []
   },
   "source": [
    "### BASIC MODEL (NO HPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6fa7e26e-bda0-4988-b044-ff6a03618153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- BEST SCORES ---\n",
      "                train             val       difference\n",
      "rmsle        -0.00407        -0.02054          0.01647\n",
      "rmse  154311489.74082 808284019.05005 -653972529.30922\n",
      "mae        6774.71075     18429.64540     -11654.93465\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Paramètres du modèle: {'bootstrap': True, 'ccp_alpha': 0.0, 'criterion': 'squared_error', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Saving model ---\n",
      "--- rf model saved to model_dump/rf_house_baseline_squared_error_True_-0.02054_04-02-2022_20:19:07.pkl---\n",
      "CPU times: user 2.1 s, sys: 12 ms, total: 2.11 s\n",
      "Wall time: 2.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "saver_params = dict(\n",
    "    dataset=dataset,\n",
    "    model_name=\"rf\",\n",
    "    objective=\"squared_error\",\n",
    "    toScale=toScale,\n",
    "    init_time=init_time,\n",
    "    columns_used=all_cols,\n",
    "    Preprocess=Preprocess,\n",
    "    preprocessing_path=scaler_name,\n",
    "    categorical=categorical,\n",
    ")\n",
    "# --- --- --- BASELINE RF --- --- ---\n",
    "if toFitRF:\n",
    "    model, kind, best_score = fit_baseline_model(\n",
    "        train_rf_classification,\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        pass_val=False,\n",
    "        params=None,\n",
    "    )\n",
    "\n",
    "    scores_df = get_results(model, data_splits)\n",
    "    # SAVE RESULTS ------\n",
    "    save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433b924e-9efc-4b18-b162-3b48458cd99b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5305496-c1c7-4ee3-8428-aed5ea0528f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 912 candidates, totalling 2736 fits\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# --- --- --- RF GRID SEARCH --- --- ---\n",
    "if toFitRF:\n",
    "    kind = \"grid\"\n",
    "\n",
    "    search = fit_grid_model(\n",
    "        train_rf_classification,\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        grid_params=rf_params,\n",
    "        grid_search_kwargs=grid_search_kwargs,\n",
    "        pass_val=False,\n",
    "        params=None,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # REFIT TO GET TRAINING ERROR AT EACH STEP ------\n",
    "\n",
    "    model = refit_with_params(\n",
    "        train_rf_classification,\n",
    "        search.best_params_,\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        pass_val=False,\n",
    "    )\n",
    "    # Score model ---\n",
    "    scores_df = get_results(model, data_splits)\n",
    "    best_score = search.best_score_\n",
    "    # Save model ---\n",
    "    model_path = save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )\n",
    "    # Save grid search results ---\n",
    "    save_grid(model_path=model_path, search=search, **saver_grid_params)\n",
    "    # boost.get_booster().feature_names= important_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de5fa8a-f551-4a9e-bfe3-18270ce751e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### REFIT on subsample of cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864224a8-aa00-41d0-af17-605eefc1fcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if toFitRF:\n",
    "    model, important_cols, subset, best_score = refit_with_selection(\n",
    "        train_rf_classification,\n",
    "        [(X_train, y_train), (X_validation, y_validation)],\n",
    "        model_with_importances=model,\n",
    "        all_cols=all_cols,\n",
    "        grid_params=rf_params,\n",
    "        grid_search_kwargs=grid_search_kwargs,\n",
    "        pass_val=False,\n",
    "        params=None,\n",
    "        best_params=search.best_params_,\n",
    "        th=0.001,\n",
    "        verbose=False,\n",
    "    )\n",
    "    data_splits_th = [\n",
    "        (data_splits[0][0][:, subset], data_splits[0][1]),\n",
    "        (data_splits[1][0][:, subset], data_splits[1][1]),\n",
    "        (data_splits[2][0][:, subset], data_splits[2][1]),\n",
    "    ]\n",
    "\n",
    "    scores_df = get_results(model, data_splits_th)\n",
    "    # Save model ---\n",
    "    kind = \"refit\"\n",
    "    model_path = save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )\n",
    "    # Save grid search results ---\n",
    "    # save_grid(model_path=model_path, search=search, **saver_grid_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5064110c-cb60-4d11-bd26-af84038d9aba",
   "metadata": {
    "tags": []
   },
   "source": [
    "## SVM "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db58ca93-29a5-4e9a-88d0-732c8a9b8d95",
   "metadata": {
    "tags": []
   },
   "source": [
    "### BASELINE SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1d7ebe1e-12b5-4dd8-aec0-49a892bcdefb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 4.77 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "saver_params = dict(\n",
    "    dataset=dataset,\n",
    "    model_name=\"svm\",\n",
    "    objective=\"misclassification\",\n",
    "    toScale=toScale,\n",
    "    init_time=init_time,\n",
    "    columns_used=all_cols,\n",
    "    Preprocess=Preprocess,\n",
    "    preprocessing_path=scaler_name,\n",
    "    categorical=categorical,\n",
    ")\n",
    "\n",
    "# --- --- --- BASELINE RF --- --- ---\n",
    "if toFitSVM:\n",
    "    model, kind, best_score = fit_baseline_model(\n",
    "        train_svr_classification,\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        pass_val=False,\n",
    "        params=None,\n",
    "    )\n",
    "\n",
    "    scores_df = get_results(model, data_splits)\n",
    "    # SAVE RESULTS ------\n",
    "    save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720fc626-861a-4983-8799-7a52a503670a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d4e53fb-2e8c-43a3-b886-f455cadf3fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 0 ns, total: 2 µs\n",
      "Wall time: 4.77 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# --- --- --- SVM GRID SEARCH --- --- ---\n",
    "if toFitSVM:\n",
    "    kind = \"grid\"\n",
    "\n",
    "    search = fit_grid_model(\n",
    "        train_svr_classification,\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        grid_params=svm_params,\n",
    "        grid_search_kwargs=grid_search_kwargs,\n",
    "        pass_val=False,\n",
    "        params=None,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # REFIT TO GET TRAINING ERROR AT EACH STEP ------\n",
    "\n",
    "    model = search.best_estimator_\n",
    "    # Score model ---\n",
    "    scores_df = get_results(model, data_splits)\n",
    "    best_score = search.best_score_\n",
    "    # Save model ---\n",
    "    model_path = save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )\n",
    "    # Save grid search results ---\n",
    "    save_grid(model_path=model_path, search=search, **saver_grid_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53356a01-d3c8-459e-80e7-a2b7c3eec8f2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0159fd90-d2c3-4f60-9c80-c7b8fd667149",
   "metadata": {
    "tags": []
   },
   "source": [
    "### BASELINE MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7bf43b-5d3a-4624-8b19-f7fd6a459d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_kwargs = dict(\n",
    "    scoring=\"neg_mean_absolute_error\", n_jobs=cpus_to_use, refit=True, cv=skf, verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19ac80fa-5401-4541-a2ba-2870ee955369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7 µs, sys: 0 ns, total: 7 µs\n",
      "Wall time: 12.4 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "saver_params = dict(\n",
    "    dataset=dataset,\n",
    "    model_name=\"mlp\",\n",
    "    objective=\"mae\",\n",
    "    toScale=toScale,\n",
    "    init_time=init_time,\n",
    "    columns_used=all_cols,\n",
    "    Preprocess=Preprocess,\n",
    "    preprocessing_path=scaler_name,\n",
    "    categorical=categorical,\n",
    ")\n",
    "\n",
    "# --- --- --- BASELINE MLP --- --- ---\n",
    "if toFitMLP:\n",
    "    model, kind, best_score = fit_baseline_model(\n",
    "        train_mlp_classification,\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        pass_val=False,\n",
    "        params=None,\n",
    "    )\n",
    "\n",
    "    scores_df = get_results(model, data_splits)\n",
    "    # SAVE RESULTS ------\n",
    "    save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3a44aa-bbd7-4245-9315-48b81c607cc6",
   "metadata": {
    "tags": []
   },
   "source": [
    "### GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9b06762-141c-48f6-abb2-7d89fc1e96ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 6.44 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# --- --- --- SVM GRID SEARCH --- --- ---\n",
    "if toFitMLP:\n",
    "    kind = \"grid\"\n",
    "\n",
    "    search = fit_grid_model(\n",
    "        train_mlp_classification,\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        grid_params=mlp_params,\n",
    "        grid_search_kwargs=grid_search_kwargs,\n",
    "        pass_val=False,\n",
    "        params=None,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # REFIT TO GET TRAINING ERROR AT EACH STEP ------\n",
    "    model = search.best_estimator_\n",
    "    # Score model ---\n",
    "    scores_df = get_results(model, data_splits)\n",
    "    best_score = search.best_score_\n",
    "    # Save model ---\n",
    "    model_path = save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )\n",
    "    # Save grid search results ---\n",
    "    save_grid(model_path=model_path, search=search, **saver_grid_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee426434-3f7c-4088-81dd-861643127a0b",
   "metadata": {},
   "source": [
    "## END "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0f22c09b-4b50-4819-9dad-ffc200e71b7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ EXECUTION TIME ------\n",
      "days: 0 hours: 0 minutes: 1\n"
     ]
    }
   ],
   "source": [
    "# PRINT EXECUTION TIME ------\n",
    "e = datetime.now()  # end time\n",
    "delta = e - s  # timedelta\n",
    "# extract ---\n",
    "days = delta.days\n",
    "seconds = delta.seconds\n",
    "# calcultate hours, minutes\n",
    "hours = seconds // 3600\n",
    "minutes = (seconds // 60) % 60\n",
    "print(\"------ EXECUTION TIME ------\")\n",
    "print(\"days:\", days, \"hours:\", hours, \"minutes:\", minutes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
