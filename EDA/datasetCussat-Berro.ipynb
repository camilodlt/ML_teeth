{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRID SEARCH BY CROSS VALIDATION \n",
    "# Analyse de la relation entre l'âge et la maturité des dents\n",
    "\n",
    "Le dataset contient l'état, déterminé par un expert médical, de plusieurs dents par patient. \n",
    "\n",
    "8 dents sont étudiées (VAL_I1, VAL_I2, VAL_C1, VAL_P1, VAL_P2, VAL_M1, VAL_M2, VAL_M3), chacune de ses dents ont un score de maturité (0, 1, A, B, C, D, E, F, G, H), 0 étant l'état le moins mature, 8 étant l'état le plus mature. \n",
    "\n",
    "Le dataset contient aussi l'âge et le sexe du patient. \n",
    "\n",
    "Nous considérons l'âge comme la variable dépendente dans cette étude, les autres variables (hors *ID*) seront explicatives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS ------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nbformat\n",
    "\n",
    "    #* Sklearn ---\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "\n",
    "    #* Graphics --- \n",
    "pd.options.plotting.backend = \"plotly\" # must have plotly installed + nbformat \n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings ---\n",
    "PATH= \"dataset.csv\"\n",
    "KNNImputerNeighbors=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Charger le dataset dans un dataframe Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LECTURE ------\n",
    "dataset=pd.read_csv(PATH, sep=\";\")\n",
    "\n",
    "# CAST TO CATEGORY ------\n",
    "for i in dataset.columns[3:]:\n",
    "    dataset[i]= dataset[i].astype(\"category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supprimer la colonne ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROP ID ------\n",
    "dataset.drop(labels=['ID'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aperçu de la table: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séparer les colonnes en :\n",
    "### a) X pour le sexe et la maturité de chacune des dents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataset.loc[:,dataset.columns!=\"PAT_AGE\"] # separer X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) Y pour l’âge qui correspond à la colonne à prédire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=dataset[\"PAT_AGE\"] # separer Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remplacer les lettres pour la maturité dentaire par des valeurs : [A, 2], [B, 3], [C, 4], [D, 5], [E, 6], [F, 7], [G, 8] et [H, 9]. Les observations doivent toutes être du type numérique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Représentation numérique pour des variables catégoriques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous exploitons le caractère odinaire des *scores de maturité*, ainsi, nous assignons une valeur numérique à chaque score de maturité dentale. \n",
    "\n",
    "En adoptant cette approche, nous supposons que **l'augmentation de la gravité de la maturité des dents est linéaire** entre les différents scores. En d'autres termes, la différence d'état de la dent (delta de gravité observée) est la même entre *A* et *B* qu'entre *B* et *C*. Cette supposition est importante. \n",
    "\n",
    "De ce fait, nous accordons des valeurs de 0 à 9 à chaque état dentaire (0,1,A,B...) respectivement. \n",
    "\n",
    "Le résultat est le suivant, ce *mapping* sera utilisé:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CATEGORIES ORDINALES ------\n",
    "categories = [\"0\", \"1\", \"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\"]\n",
    "categoriesDict = {ith:label for ith,label in enumerate(categories)} # 0:0 1:1 2:A ... \n",
    "\n",
    "# NAME OF ORDINAL VARS ------\n",
    "categoric=dataset.columns[2:]\n",
    "nCategoric=len(categoric)  # Size\n",
    "\n",
    "# *Print --- \n",
    "print(\"Replace categories given this rule :\" ,categoriesDict) # only for illustration, OrdinalEncoder does the work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCORES (ETATS) SONT PARTAGES POUR TOUTES LES DENTS -----\n",
    "catMatrix=[]\n",
    "for i in range(0,nCategoric,1):\n",
    "    catMatrix.append(categories) # Matrice (n_colonnes,n_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPROCESSING CAT TO NUM ------\n",
    "ordEncoder = preprocessing.OrdinalEncoder(categories=catMatrix, unknown_value= np.nan,handle_unknown='use_encoded_value') # créer le encoder. \n",
    "encoded=ordEncoder.fit_transform(X[categoric]) # apply transformation. \n",
    "EncodedDataset= pd.DataFrame(encoded,columns=categoric) # To DF\n",
    "EncodedDataset=pd.concat([X[\"PAT_SEX\"].reset_index(drop=True), EncodedDataset], axis=1) # Add non transformed vars. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toutes les colonnes sont numériques: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ALL COLUMNS ARE NUMERIC ------\n",
    "EncodedDataset.dtypes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remplacer les données manquantes de la feature VAL_M3 par zéro (dent absente)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La colonne VAL_M3 est la moins complète, c'est à dire, qu'elle a le plus grand nombre de valeur manquantes. \n",
    "\n",
    "Nous allons remplacer toutes ses valeurs par 0, en d'autres termes, nous traduisons la valeur nulle pour cette dent comme représentant le fait que la dent n'a pas encore poussé. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nMissingM3= pd.isna(EncodedDataset[\"VAL_M3\"]).sum()\n",
    "print(f\"Pourcentage de valeur manquantes de la colonne VAL_M3: {np.round(nMissingM3/EncodedDataset.shape[0]*100)}% ({nMissingM3})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill VAL_M3 with 0 ---\n",
    "EncodedDataset[\"VAL_M3\"].fillna(0, inplace=True)\n",
    "\n",
    "print(\"Répartition de la maturité dentaire de la colonne VAL_M3\")\n",
    "EncodedDataset[\"VAL_M3\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous observons qu'après imputation, la maturité dentaire 0 est prédominante. (avant : 1097 zeros, après imputation : 1180 zeros). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## En utilisant KNN_imputer, remplacer les données manquantes par une prédiction réalisée par l’algorithme des KNN en utilisant les autres features. Vous utiliserez pour cela un voisinage de 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse du renseignement des variables \n",
    "\n",
    "D'abord, nous souhaitons connaître le nombre de NA par colonne.\n",
    "\n",
    "Nous avions déjà remplacer les valeurs manquantes pour la colonne VAL_M3, 1097 valeurs ont été remplacées par 0. VAL_M3 était la variable avec le plus de valeur manquantes.\n",
    "\n",
    "VAL_PM2 et VAL_I1 sont les colonnes restantes avec le plus de valeurs nulles, 12% pour VAL_PM2 et 11% pour VAL_I1. Toutes les autres colonnes ont moins de 10% de valeurs manquantes. \n",
    "\n",
    "Toutes les occurences sont renseignées pour la variable du sexe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of NAs ---\n",
    "naOccurencies=pd.isna(EncodedDataset).sum().reset_index()\n",
    "naOccurencies.columns= [\"Dents\",\"Nombre_NA\"]\n",
    "naOccurencies.sort_values(by=\"Nombre_NA\", inplace=True) # sorting\n",
    "naOccurencies[\"PctNA\"]=naOccurencies[\"Nombre_NA\"].divide(len(EncodedDataset))\n",
    "\n",
    "# PLOTTING ------\n",
    "fig =px.bar(naOccurencies,x= \"Dents\",y=\"PctNA\" )\n",
    "fig.update_layout(title= \"Nombre de valeurs nulles par colonne\")\n",
    "pio.show(fig, renderer=\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation des valeurs nulles par *KNN*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous proposons une stratégie d'imputation par la méthode des plus proches voisins *KNN*. \n",
    "\n",
    "Le *KNNImputer* nous permet de remplacer les valeurs nulles par des valeurs cohérentes en fonction du comportement/score des voisins proches. \n",
    "\n",
    "Nous avons choisit, en hyperparamètre, 5 voisins. Cette valeur est souvent choisit pour l'imputation, nous considérons que ce choix est robuste (un bon *trade off*) entre généralisation (réduire la variance) et voisinage (nous voulons que les plus proches, donc, réduire le bias).\n",
    "\n",
    "Nous avons donc préféré cette méthode plutôt qu'un SimpleImputer (avec la moyenne ou la médianne). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPUTER KNN WITH 3 N ------\n",
    "knnImputer = KNNImputer(n_neighbors=KNNImputerNeighbors)\n",
    "imputed=knnImputer.fit_transform(EncodedDataset)\n",
    "# CAST TO DF ------\n",
    "imputedDF=pd.DataFrame(imputed, columns=EncodedDataset.columns) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Séparer le dataset en un dataset d’entrainement [X_train, y_train] et un dataset de test [X_test, y_test]. Le split doit être de 80 / 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test= train_test_split(imputedDF,y, test_size= 0.2, random_state=123)\n",
    "\n",
    "print(f\"Nombre de lignes pour entrainement: {len(X_train)}, correspond à {round(len(X_train)/len(imputedDF),2)*100}% du dataset complet\")\n",
    "print(f\"Nombre de lignes pour la validation: {len(X_test)}, correspond à {round(len(X_test)/len(imputedDF),2)*100}% du dataset complet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cherchons la meilleure méthode permettant de prédire l’âge en fonction du sexe et de la maturité dentaire.\n",
    "\n",
    "Pour cela, nous allons utiliser GridSearchCV et Pipeline de la bibliothèque SKLearn pour explorer largement les possibilités de préprocessing (réduction de dimensionnalité) couplées avec quelques algorithmes d’apprentissage supervisés. Tous les entrainements doivent être réalisés sur le dataset d’entrainement et le score doit être comparé au score du pipeline sur le dataset de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Créer un pipeline intégrant une PCA et une régression linéaire. Explorer les valeurs du paramètre n_components de la PCA qui donne le meilleur de régression linéaire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons utiliser une PCA comme méthode de *preprocessing* avant d'utiliser une regression lineaire pour les prédictions. \n",
    "\n",
    "La métrique que nous souhaitons optimiser est la moyenne des erreurs au carré. Nous choisissons les paramètres pour lesquels la moyenne des pertes du *cross validation test set* est la plus basse.\n",
    "\n",
    "Enfin, avec les meilleurs paramètres, nous évaluons la performance avec le vrai *test set*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIPELINE ----- \n",
    "p1= Pipeline([('PCA', PCA(random_state=123)),('Regression', LinearRegression())])\n",
    "    #* Params --- \n",
    "params= {\n",
    "    'PCA__n_components': np.arange(1,10).tolist()\n",
    "    }\n",
    "\n",
    "# FIT PIPELINE with Gridsearch ---\n",
    "clf = GridSearchCV(p1, params, # pipeline + params\n",
    "                   n_jobs=-1, # cpus\n",
    "                   scoring=\"neg_root_mean_squared_error\")# Scoring \n",
    "clf.fit(X_train, y_train);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #* Extract results --- \n",
    "results= pd.DataFrame(clf.cv_results_)\n",
    "results.sort_values(\"mean_test_score\",ascending=False, inplace=True)\n",
    "results[\"mean_test_score\"]=results[\"mean_test_score\"]*-1 # non negative SS\n",
    "\n",
    "# PLOT RESULTS ------\n",
    "fig=px.line(results,x='param_PCA__n_components', y=\"mean_test_score\", error_y=\"std_test_score\") \n",
    "fig.update_layout(title=\"Nombre de composants principaux vs CV test score (negative root mean squared error)\")\n",
    "fig.show(renderer=\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il semblerait que garder 6, 7 ou 8,9 composants principaux aboutit à des résultats très similaires avec la regression linéaire comme prédicteur. \n",
    "\n",
    "Nous choissons le meilleur paramètre, qui dans ce cas est 9 composants principaux. Toutefois, ceci présente peu d'avantages parce que nous n'avons pas réussi à réduire la dimensionalité de nos données, donc, nous n'avons pas capturer suffisament de variance à l'aide de moins de variables : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Meilleurs paramètres : {clf.best_params_}\")\n",
    "print(f\"Meilleur CV test score : {clf.best_score_}\")\n",
    "print(f\"Test Score  (negative Sum of Squares) avec 20% des données qui n'ont pas servi à l'entraînement: {clf.score(X_test, y_test)}\") \n",
    "print(f\"Train Score (negative Sum of Squares) : {clf.score(X_train, y_train)}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)Créer un pipeline intégrant une PCA et un KNN. En utilisant GridSearch, explorer l’ensemble des couples de paramètres n_components (pour la PCA), n_neighbors (pour KNN) et weights (pour KNN) donnant les meilleurs résultats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous changeons notre algorithme d'apprentissage supervisé, cette fois-ci, nous utilisons un prédicteur par plus proches voisins: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PIPELINE ----- \n",
    "p2= Pipeline([('PCA', PCA(random_state=123)),('KNN', KNeighborsRegressor())])\n",
    "    #* Params --- \n",
    "params= {\n",
    "        'PCA__n_components': np.arange(1,10).tolist(), # PCA \n",
    "        'KNN__weights': [\"uniform\", \"distance\"], # KNN\n",
    "        'KNN__n_neighbors': np.arange(1,100) # KNN\n",
    "        }\n",
    "\n",
    "# FIT PIPELINE with Gridsearch ---\n",
    "clf = GridSearchCV(p2, params, n_jobs=-1,scoring=\"neg_root_mean_squared_error\")\n",
    "clf.fit(X_train, y_train);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette fois-ci nous avons plus de paramètres à prendre en compte pour nos choix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #* Extract results --- \n",
    "results= pd.DataFrame(clf.cv_results_)\n",
    "results.sort_values(\"mean_test_score\",ascending=False, inplace=True)\n",
    "results[\"mean_test_score\"]=results[\"mean_test_score\"]*-1 # non negative\n",
    "\n",
    "# PLOT RESULTS ------\n",
    "fig=px.scatter(results,x= \"param_KNN__n_neighbors\", y=\"mean_test_score\", symbol=\"param_KNN__weights\",\n",
    "               color=\"param_PCA__n_components\", \n",
    "              size=np.repeat(1,results.shape[0]),\n",
    "              size_max=12,\n",
    "              symbol_sequence=[\"circle-open\",\"arrow-bar-right\"])\n",
    "fig.update_layout(height=500, title =\"CV Test Scores from GridSearch. <br>     Form = weight (arrow is 'distance', triangle is 'uniform'). <br>     Color= N_components\", margin=dict(t=110))\n",
    "fig.show(renderer=\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons examiner les résultats: \n",
    "\n",
    "**Nombre de voisins: (axe abscisses)**\n",
    "\n",
    "Avant 6 ou 7 *nearest neighbors*, l'erreur est élevée quelles que soient les valeurs des autres paramètres (poids des voisins et nombre de composants principaux).\n",
    "\n",
    "Après 7 voisins, et en fonction des choix des autres paramètres, des bons scores sont possibles. \n",
    "\n",
    "**Type de poids des voisins: (triangle ou cercle)**\n",
    "\n",
    "Nous observons un phénomène qui est assez logique: plus on augmente le nombre de voisins, plus le poids par distance (au lieu d'un poid unique) devient important. \n",
    "\n",
    "Visuellement, à partir de 35 plus proches voisins, pondérer les voisins par sa distance euclidienne permet de garder des scores bas, au contraire, continuer à pondérer tous les voisins de la même manière augmente notre score de perte. \n",
    "\n",
    "Cependant, aux alentours de 20 ($\\pm$ 8) *nearest neighbors*, il paraît qu'un poid uniforme réduit marginalement la perte. \n",
    "\n",
    "**Nombre de composants principaux: (couleur)**\n",
    "\n",
    "Le choix du bon nombre de composants semble difficile. En garder 1 seul composant aboutit a des erreurs élevés quelles que soient les autres paramètres, en effet, ce choix est trop restrictif. \n",
    "\n",
    "Toutefois, pour les choix restant (2-9 composants), plusieurs combinaisons de paramètres aboutissent à des bon résultats. Plusieurs fois, 2 composants sont suffisants si la pondération est uniforme et le nombre de voisins n'est pas très élevé (ce choix serait intéressant pour visualiser les données ainsi que pour des questions de rapidité).\n",
    "\n",
    "\n",
    "Nous choissons les paramètres qui ont permis d'obtenier l'erreur le plus bas, nous considérons si ce choix est en accord à nos observations: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Meilleurs paramètres : {clf.best_params_}\")\n",
    "print(f\"Meilleur CV test score : {clf.best_score_}\")\n",
    "print(f\"Test Score  (negative Sum of Squares) avec 20% des données qui n'ont pas servi à l'entraînement: {clf.score(X_test, y_test)}\") \n",
    "print(f\"Train Score (negative Sum of Squares) : {clf.score(X_train, y_train)}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Ajouter un scaler en début pipeline et tester, en plus des paramètres précédents les 4 fonctions de normalisation StandardScaler, MinMaxScaler, Normalizer et MaxAbsScaler."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous évaluons maintenant l'impact de standardiser nos données par plusieurs moyens: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scalers to try --- \n",
    "scalers= [\"StandardScaler\",\"MinMaxScaler\",\"Normalizer\",\"MaxAbsScaler\"]\n",
    "resultsList= []\n",
    "for scaleProcedure in scalers: \n",
    "    print(f\"------ Fitting Pipeline with {scaleProcedure} ------\")\n",
    "    p2= Pipeline([(scaleProcedure, eval(scaleProcedure)()), # evaluate the scaler string\n",
    "                  ('PCA',PCA()),\n",
    "                  ('KNN', KNeighborsRegressor())])\n",
    "\n",
    "    params= {\n",
    "            'PCA__n_components': np.arange(1,10).tolist(),\n",
    "            'KNN__weights': [\"uniform\", \"distance\"],\n",
    "            'KNN__n_neighbors': np.arange(1,100)\n",
    "            }\n",
    "\n",
    "    clf = GridSearchCV(p2, params, n_jobs=-1,scoring=\"neg_root_mean_squared_error\")\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Results ---\n",
    "    results= pd.DataFrame(clf.cv_results_)\n",
    "    results.sort_values(\"mean_test_score\",ascending=False, inplace=True)\n",
    "    results[\"mean_test_score\"]=results[\"mean_test_score\"]*-1 \n",
    "    results[\"ScalerUsed\"]= scaleProcedure\n",
    "    \n",
    "    # Save them --- \n",
    "    resultsList.append(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons de nombreuses combinaisons (1782 (9\\*2\\*99) paramètres pour chaque fonction de standardisation, donc 1782\\*4). Nous choisissons de visualiser uniquement les 100 combinaisons qui ont aboutit aux meilleurs résultats du *cross validation test set*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONCAT AND FILTER BEST 100 ------ \n",
    "top100params=pd.concat(resultsList).query(\"rank_test_score<100\")\n",
    "top100params.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette fois-ci, nous ne visualisons pas les paramètres du nombre de composants ou du type de pondération des voisins. \n",
    "\n",
    "Par contre, nous affichons chaque méthode de standardisation à l'aide de couleurs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT RESULTS -----\n",
    "fig=px.scatter(top100params,x=\"param_KNN__n_neighbors\",  y =\"mean_test_score\" ,color=\"ScalerUsed\") #, error_y=\"std_test_score\" ) \n",
    "fig.show(renderer=\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons observer directement que pour toutes les combinaisons de paramètres, la méthode *Normalizer* a produit des erreurs plus élevées que les autres algorithmes (la norme l2 est utilisée par defaut).\n",
    "\n",
    "Ensuite, le *MaxAbsScaler*, même si compétitif, produit des erreurs moins avantageux que les deux autres méthodes. \n",
    "\n",
    "Enfin, le StandardScaler et le MinMaxScaler aboutissent aux meilleurs scores, notamment, avec un nombre de voisins compris entre 8 et 17. \n",
    "\n",
    "Voyons les meilleurs paramètres obtenus: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract best params ---\n",
    "best =top100params.iloc[np.argmin(top100params[\"mean_test_score\"]),:]\n",
    "bestKnnNeighbors= best[\"param_KNN__n_neighbors\"]\n",
    "bestKnnWeights= best[\"param_KNN__weights\"]\n",
    "bestPcaNComponents= best[\"param_PCA__n_components\"]\n",
    "bestScaler= best[\"ScalerUsed\"]\n",
    "bestScore= best[\"mean_test_score\"]\n",
    "\n",
    "# Refit --- \n",
    "BestPipe= Pipeline([(bestScaler, eval(bestScaler)()), # evaluate the scaler string\n",
    "                  ('PCA',PCA()),\n",
    "                  ('KNN', KNeighborsRegressor())])\n",
    "bestParams= {\n",
    "            'PCA__n_components': bestPcaNComponents,\n",
    "            'KNN__weights': bestKnnWeights,\n",
    "            'KNN__n_neighbors': bestKnnNeighbors\n",
    "            }\n",
    "BestPipe.set_params(**bestParams) # Use best params founded by GridSearch \n",
    "BestPipe.fit(X_train, y_train)\n",
    "predTrain=BestPipe.predict(X_train) # predictions for training\n",
    "predTest=BestPipe.predict(X_test) # predictions for testing \n",
    "\n",
    "# SCORE ---\n",
    "scoreTrain=np.sqrt(mean_squared_error(predTrain, y_train))\n",
    "scoreTest=np.sqrt(mean_squared_error(predTest, y_test))\n",
    "\n",
    "# Print best results ---\n",
    "print(f\"Meilleurs paramètres : N_Neighbors : {bestKnnNeighbors}, Weight: {bestKnnWeights}, N_components: {bestPcaNComponents}, Scaler: {bestScaler}\")\n",
    "print(f\"Meilleur CV test score : {bestScore}\")\n",
    "print(f\"Test Score  (negative Sum of Squares) avec 20% des données qui n'ont pas servi à l'entraînement: {scoreTest}\") \n",
    "print(f\"Train Score (negative Sum of Squares) : {scoreTrain}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utiliser une méthode de standardisation a amélioré nos scores.\n",
    "\n",
    "D'une part, nous avons réduit la dimensionalité de nos données mais pas drastiquement (le pipeline précédent en avait gardé que 2 composants, le premier pipeline en avait garder 9!). D'autre part, le test score par *cross validation* et très proche du train score. \n",
    "\n",
    "**Comparaison de entre Pipelines**\n",
    "\n",
    "Nous pouvons donc comparer nos scores pour le train set (20% n'ayant pas été utilisé pour l'entraînement) entre pipelines: \n",
    "- PCA + regressions linéaire: Meilleur Test Score 2.6592\n",
    "- PCA + Knnregressor : Meilleur Test Score : 1.9001\n",
    "- MinMaxScaler + PCA + Knnregressor : Meilleur Test Score : 1.8577\n",
    "\n",
    "Donc, nous avons améliore notre pouvoir prédictif à chaque étape, notamment, grâce à la recherche de paramètres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse des erreurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre modèle, même s'il est simple (15 *neighbors*), obtient un bon score (root mean squared error) de 1.85, il fait donc des erreurs peu considérables, en moyenne. \n",
    "\n",
    "Toutefois, l'erreur de prédiction n'est pas le même pour toutes les âges, en effet, nos prédictions ont plus de variabilité lorsqu'il s'agit d'individu âgés. A l'inverse, les erreurs sont faibles pour les individus jeunes. Ceci est peut-être du à la distribution de l'âge dans notre dataset, en effet, des âges élevés sont sous-représentés par rapport aux jeunes patients. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST ERRORS vs GROUND TRUTH ------\n",
    "preds= pd.DataFrame({\"Truth\":y_test, \"Pred\": predTest}).reset_index() # PREDICTIONS TEST \n",
    "fig= px.scatter(preds, x=\"Truth\", y= \"Pred\")\n",
    "fig.update_layout(title=\"Pred vs Ground truth, ideal would be an straight line\")\n",
    "fig.show(renderer=\"notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A nouveau nous voyons que le résidu augmente avec l'âge des patients (résidus en forme de cone). \n",
    "\n",
    "De plus, nous observons que les erreurs sont faites à la hausse comme à la baisse, cependant, pour les individus les plus âgés de notre dataset, nous observons que notre modèle prédit constamment un âge trop faible. \n",
    "\n",
    "En effet, on peut aussi visualiser cet effet grâce à un sort d'effet de plateau horizontal dans le graphique précedent (les valeurs prédictions n'augementent pas alors que l'âge augmente) ou par l'absence de résidu positif pour les âges les plus élevés dans le graphique suivant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# POSITIVE VS NEGATIVE ERRORS VS AGE ------\n",
    "preds[\"res\"]=preds[\"Pred\"]-preds[\"Truth\"] # residuals\n",
    "preds[\"abs_res\"]= np.abs(preds[\"res\"]) \n",
    "preds[\"sign_res\"]= np.where(preds[\"res\"]<0,\"negative\",\"positive\") # sign\n",
    "fig= px.scatter(preds, x=\"Truth\", y= \"res\",color=\"sign_res\")\n",
    "fig.update_layout(title=\"Residuals vs Ground Truth, A larger distance to 0 means a larger error prediction\")\n",
    "fig.show(renderer=\"notebook\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "488px",
    "width": "262px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
