{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9dd90d53",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at '<a href=\"#papermill-error-cell\">In [25]</a>'.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d87c22-4387-4aa1-9ad5-d7c515adefd2",
   "metadata": {
    "papermill": {
     "duration": 0.031128,
     "end_time": "2022-02-06T21:07:07.331926",
     "exception": false,
     "start_time": "2022-02-06T21:07:07.300798",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# HOUSE PRICES TRAINER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c329355-4ccf-4ef3-88e1-b85c76e3f51b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T21:07:07.394747Z",
     "iopub.status.busy": "2022-02-06T21:07:07.394332Z",
     "iopub.status.idle": "2022-02-06T21:07:07.588870Z",
     "shell.execute_reply": "2022-02-06T21:07:07.588182Z"
    },
    "papermill": {
     "duration": 0.230513,
     "end_time": "2022-02-06T21:07:07.589067",
     "exception": false,
     "start_time": "2022-02-06T21:07:07.358554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.9.7\r\n"
     ]
    }
   ],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eab36b8-9bf8-43de-9fc6-456c74b6a0bd",
   "metadata": {
    "papermill": {
     "duration": 0.026419,
     "end_time": "2022-02-06T21:07:07.649234",
     "exception": false,
     "start_time": "2022-02-06T21:07:07.622815",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## DATA AND GLOBAL PARAMETERS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f58c2b-ed1f-4287-a6aa-4d83d0f0b263",
   "metadata": {
    "papermill": {
     "duration": 0.025374,
     "end_time": "2022-02-06T21:07:07.700768",
     "exception": false,
     "start_time": "2022-02-06T21:07:07.675394",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdd4665b-d318-44ad-90e0-d2bb500f9c25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T21:07:07.760553Z",
     "iopub.status.busy": "2022-02-06T21:07:07.759981Z",
     "iopub.status.idle": "2022-02-06T21:07:08.253044Z",
     "shell.execute_reply": "2022-02-06T21:07:08.253313Z"
    },
    "papermill": {
     "duration": 0.525574,
     "end_time": "2022-02-06T21:07:08.253445",
     "exception": false,
     "start_time": "2022-02-06T21:07:07.727871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LIRBARIES ------\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "# Misc\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# Combinatorics\n",
    "from itertools import product\n",
    "from pickle import dump\n",
    "\n",
    "# Matrices\n",
    "import numpy as np\n",
    "\n",
    "# DF\n",
    "import pandas as pd\n",
    "\n",
    "# Boosting machine\n",
    "import xgboost as xgb\n",
    "from IPython.display import Markdown as md\n",
    "from IPython.display import display as printmd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import (\n",
    "    make_scorer,\n",
    "    mean_absolute_error,\n",
    "    mean_squared_error,\n",
    "    mean_squared_log_error,\n",
    "    accuracy_score,\n",
    "    f1_score\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV, KFold, train_test_split\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.svm import SVC, SVR\n",
    "\n",
    "# SKLEARN ---\n",
    "# * metrics ---\n",
    "\n",
    "# * Preprocess ---\n",
    "\n",
    "# * Imputation\n",
    "\n",
    "# * CV ---\n",
    "\n",
    "# Regression\n",
    "\n",
    "\n",
    "# utils\n",
    "base_path = \"/home/jovyan/work/TP3_TP4\"  # laptop : /home/jovyan/work/CM_ML/TP3_TP4 other tower: /home/jovyan/work/TP3_TP4\n",
    "os.chdir(base_path)\n",
    "sys.path.append(base_path)\n",
    "from utils.utils import rmsle_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae74c8f9-0436-4bd1-b8b4-9b11b9eb18b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T21:07:08.307879Z",
     "iopub.status.busy": "2022-02-06T21:07:08.307431Z",
     "iopub.status.idle": "2022-02-06T21:07:08.309503Z",
     "shell.execute_reply": "2022-02-06T21:07:08.309207Z"
    },
    "papermill": {
     "duration": 0.030415,
     "end_time": "2022-02-06T21:07:08.309584",
     "exception": false,
     "start_time": "2022-02-06T21:07:08.279169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting time and time used for files 06-02-2022_21:07:08\n"
     ]
    }
   ],
   "source": [
    "# START TIME ------\n",
    "s = datetime.now()\n",
    "# time as str\n",
    "init_time = s.strftime(\"%d-%m-%Y_%H:%M:%S\")\n",
    "print(f\"Starting time and time used for files {init_time}\")\n",
    "pd.set_option(\"display.float_format\", lambda x: \"%.5f\" % x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cde833b-9037-4544-b051-8f8776264fbd",
   "metadata": {
    "papermill": {
     "duration": 0.027822,
     "end_time": "2022-02-06T21:07:08.365872",
     "exception": false,
     "start_time": "2022-02-06T21:07:08.338050",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Helper functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3eb0f29-3e7c-4ca0-b863-532b57157a59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T21:07:08.428190Z",
     "iopub.status.busy": "2022-02-06T21:07:08.427727Z",
     "iopub.status.idle": "2022-02-06T21:07:08.429062Z",
     "shell.execute_reply": "2022-02-06T21:07:08.429346Z"
    },
    "papermill": {
     "duration": 0.035397,
     "end_time": "2022-02-06T21:07:08.429455",
     "exception": false,
     "start_time": "2022-02-06T21:07:08.394058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# FROM DATA TO MODEL DATA -----\n",
    "def preprocess_data_as_model(data, dependent, categorical):\n",
    "    # * Divide X,y ---\n",
    "    data_subset = data.drop(dependent, axis=1)\n",
    "    y = data[dependent].values\n",
    "\n",
    "    # handle categorical variables ---\n",
    "    cols_beginning = data_subset.columns.values\n",
    "\n",
    "    all_cols = cols_beginning\n",
    "    numeric_cols = data_subset.select_dtypes([\"number\"]).columns\n",
    "    numeric_cols_index = np.in1d(all_cols, numeric_cols)\n",
    "\n",
    "    categorical_cols = data_subset.select_dtypes([\"object\"]).columns\n",
    "    categorical_cols_index = np.in1d(all_cols, categorical_cols)\n",
    "\n",
    "    # Transformations ---\n",
    "    transformations = []\n",
    "\n",
    "    if categorical:\n",
    "        pass  # todo\n",
    "    else:\n",
    "        # Training cols ---\n",
    "        data_subset = data_subset.select_dtypes([\"number\"])  # drop categorical\n",
    "        all_cols = cols_beginning[numeric_cols_index]  # only numerical cols ....\n",
    "        numeric_cols_index = (\n",
    "            data_subset.columns.values != None\n",
    "        )  # apply transformation to all columns\n",
    "    return (\n",
    "        data_subset,\n",
    "        y,\n",
    "        all_cols,\n",
    "        numeric_cols,\n",
    "        numeric_cols_index,\n",
    "        categorical_cols,\n",
    "        categorical_cols_index,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a33c6740-4817-4146-b107-44a966451313",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T21:07:08.496314Z",
     "iopub.status.busy": "2022-02-06T21:07:08.495761Z",
     "iopub.status.idle": "2022-02-06T21:07:08.496967Z",
     "shell.execute_reply": "2022-02-06T21:07:08.497440Z"
    },
    "papermill": {
     "duration": 0.041111,
     "end_time": "2022-02-06T21:07:08.497608",
     "exception": false,
     "start_time": "2022-02-06T21:07:08.456497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODEL TRAINERS ------\n",
    "\n",
    "\n",
    "def train_mlp(data=None, best_params=None):\n",
    "    # * Init xgb instance ---\n",
    "    mlp = MLPRegressor(max_iter=3000, random_state=123, early_stopping=True)\n",
    "    # * Set best params, normally found by a previous Grid search ---\n",
    "    if best_params:\n",
    "        print(f\"Setting best parameters: {best_params}\")\n",
    "        mlp.set_params(**best_params)\n",
    "    if data:\n",
    "        # * Fit mlp: ((x_train,y_train)) ---\n",
    "        mlp.fit(X=data[0], y=data[1])\n",
    "    return mlp\n",
    "\n",
    "\n",
    "def train_svr(data=None, best_params=None):\n",
    "    # * Init xgb instance ---\n",
    "    svr = SVR()\n",
    "    # * Set best params, normally found by a previous Grid search ---\n",
    "    if best_params:\n",
    "        print(f\"Setting best parameters: {best_params}\")\n",
    "        svr.set_params(**best_params)\n",
    "    if data:\n",
    "        # * Fit svr: ((x_train,y_train)) ---\n",
    "        svr.fit(X=data[0], y=data[1])\n",
    "    return svr\n",
    "\n",
    "\n",
    "def train_rf(data=None, best_params=None):\n",
    "    # * Init xgb instance ---\n",
    "    rf = RandomForestRegressor()\n",
    "\n",
    "    # * Set best params, normally found by a previous Grid search ---\n",
    "    if best_params:\n",
    "        print(f\"Setting best parameters: {best_params}\")\n",
    "        rf.set_params(**best_params)\n",
    "    if data:\n",
    "        # * Fit rf: ((x_train,y_train)) ---\n",
    "        rf.fit(X=data[0], y=data[1])\n",
    "    return rf\n",
    "\n",
    "\n",
    "def train_xgb(params, data=None, best_params=None):\n",
    "    # * Init xgb instance ---\n",
    "    boost = xgb.XGBRegressor(**params)\n",
    "\n",
    "    # * Set best params, normally found by a previous Grid search ---\n",
    "    if best_params:\n",
    "        print(f\"Setting best parameters: {best_params}\")\n",
    "        boost.set_params(**best_params)\n",
    "\n",
    "    # * Fit booster: ((x_train,y_train), (x_test,y_test)) ---\n",
    "    if data:\n",
    "        boost.fit(\n",
    "            X=data[0][0],\n",
    "            y=data[0][1],\n",
    "            eval_set=data,  # Validation set for early stopping (validates on test -- last data tuple)\n",
    "            early_stopping_rounds=10,\n",
    "            verbose=0,\n",
    "            eval_metric=[\"mae\", \"rmse\", \"rmsle\"],\n",
    "        )\n",
    "    return boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c03037fe-8168-449f-815f-80a0a0595d2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T21:07:08.565048Z",
     "iopub.status.busy": "2022-02-06T21:07:08.564719Z",
     "iopub.status.idle": "2022-02-06T21:07:08.570624Z",
     "shell.execute_reply": "2022-02-06T21:07:08.570060Z"
    },
    "papermill": {
     "duration": 0.041937,
     "end_time": "2022-02-06T21:07:08.570812",
     "exception": false,
     "start_time": "2022-02-06T21:07:08.528875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_mlp_classification(data=None, best_params=None):\n",
    "    # * Init xgb instance ---\n",
    "    mlp = MLPClassifier(max_iter=3000, random_state=123, early_stopping=True)\n",
    "    # * Set best params, normally found by a previous Grid search ---\n",
    "    if best_params:\n",
    "        print(f\"Setting best parameters: {best_params}\")\n",
    "        mlp.set_params(**best_params)\n",
    "    if data:\n",
    "        # * Fit mlp: ((x_train,y_train)) ---\n",
    "        mlp.fit(X=data[0], y=data[1])\n",
    "    return mlp\n",
    "\n",
    "\n",
    "def train_svr_classification(data=None, best_params=None):\n",
    "    # * Init xgb instance ---\n",
    "    svr = SVC()\n",
    "    # * Set best params, normally found by a previous Grid search ---\n",
    "    if best_params:\n",
    "        print(f\"Setting best parameters: {best_params}\")\n",
    "        svr.set_params(**best_params)\n",
    "    if data:\n",
    "        # * Fit svr: ((x_train,y_train)) ---\n",
    "        svr.fit(X=data[0], y=data[1])\n",
    "    return svr\n",
    "\n",
    "\n",
    "def train_rf_classification(data=None, best_params=None):\n",
    "    # * Init xgb instance ---\n",
    "    rf = RandomForestClassifier(random_state=123)\n",
    "\n",
    "    # * Set best params, normally found by a previous Grid search ---\n",
    "    if best_params:\n",
    "        print(f\"Setting best parameters: {best_params}\")\n",
    "        rf.set_params(**best_params)\n",
    "    if data:\n",
    "        # * Fit rf: ((x_train,y_train)) ---\n",
    "        rf.fit(X=data[0], y=data[1])\n",
    "    return rf\n",
    "\n",
    "\n",
    "def train_xgb_classification(params, data=None, best_params=None):\n",
    "    # * Init xgb instance ---\n",
    "    boost = xgb.XGBClassifier(**params)\n",
    "\n",
    "    # * Set best params, normally found by a previous Grid search ---\n",
    "    if best_params:\n",
    "        print(f\"Setting best parameters: {best_params}\")\n",
    "        boost.set_params(**best_params)\n",
    "\n",
    "    # * Fit booster: ((x_train,y_train), (x_test,y_test)) ---\n",
    "    if data:\n",
    "        boost.fit(\n",
    "            X=data[0][0],\n",
    "            y=data[0][1],\n",
    "            eval_set=data,  # Validation set for early stopping (validates on test -- last data tuple)\n",
    "            early_stopping_rounds=10,\n",
    "            verbose=0,\n",
    "            eval_metric=[\"mae\", \"rmse\", \"rmsle\"],\n",
    "        )\n",
    "    return boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8997e70-1f93-4f22-8b3b-37667252e789",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T21:07:08.641286Z",
     "iopub.status.busy": "2022-02-06T21:07:08.640945Z",
     "iopub.status.idle": "2022-02-06T21:07:08.642442Z",
     "shell.execute_reply": "2022-02-06T21:07:08.642170Z"
    },
    "papermill": {
     "duration": 0.039597,
     "end_time": "2022-02-06T21:07:08.642533",
     "exception": false,
     "start_time": "2022-02-06T21:07:08.602936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# MODEL SAVERS ------\n",
    "def save_model(\n",
    "    model,\n",
    "    model_name,\n",
    "    dataset,\n",
    "    kind,\n",
    "    objective,\n",
    "    toScale,\n",
    "    best_score,\n",
    "    init_time,\n",
    "    columns_used,\n",
    "    Preprocess,\n",
    "    preprocessing_path,\n",
    "    categorical,\n",
    "    scores,\n",
    ") -> str:\n",
    "    print(\"\\n\")\n",
    "    print(\"--- Saving model ---\")\n",
    "    model_path = f\"model_dump/{model_name}_{dataset}_{kind}_{objective}_{toScale}_{np.round(best_score,5)}_{init_time}.pkl\"\n",
    "\n",
    "    dump(\n",
    "        {  # options\n",
    "            \"scaled\": toScale,\n",
    "            \"categorical\": categorical,\n",
    "            # processing and model\n",
    "            \"columns_used\": columns_used,\n",
    "            \"preprocess\": Preprocess,\n",
    "            \"model\": model,\n",
    "            \"preprocessing_path\": preprocessing_path,\n",
    "            # outcome\n",
    "            \"scores\": scores,\n",
    "        },\n",
    "        open(model_path, \"wb\"),\n",
    "    )\n",
    "\n",
    "    print(f\"--- {model_name} model saved to {model_path}---\")\n",
    "    return model_path\n",
    "\n",
    "\n",
    "def save_grid(\n",
    "    model_path,\n",
    "    model_name,\n",
    "    dataset,\n",
    "    init_time,\n",
    "    preprocessing_path,\n",
    "    toScale,\n",
    "    categorical,\n",
    "    search,\n",
    "):\n",
    "\n",
    "    res = pd.DataFrame(search.cv_results_)\n",
    "\n",
    "    # * Save estimator ---\n",
    "    res[\"model_path\"] = model_path\n",
    "\n",
    "    # * Did we scale ?\n",
    "    if preprocessing_path:\n",
    "        res[\"preprocessing_path\"] = preprocessing_path\n",
    "    else:\n",
    "        res[\"preprocessing_path\"] = \"no preprocess\"\n",
    "\n",
    "    res[\"categorical\"] = categorical\n",
    "\n",
    "    # * To csv ---\n",
    "    grid_name = f\"grid_search/Grid_{model_name}_{dataset}_{init_time}.csv\"\n",
    "    res.to_csv(grid_name)\n",
    "    print(f\"--- Grid search results saved to {grid_name}---\")\n",
    "\n",
    "\n",
    "def score_model(model, data):\n",
    "    \"\"\"\n",
    "    data = ((xtrain, ytrain), (x_val, y_val), (x_test, y_test))\n",
    "    \"\"\"\n",
    "    splits = [\"train\", \"val\", \"test\"]\n",
    "    scores = {}\n",
    "    for i, split in enumerate(splits):\n",
    "        metrics = {}\n",
    "        metrics[\"accuracy\"] = accuracy_score(model.predict(data[i][0]), data[i][1])\n",
    "        metrics[\"f1\"] = f1_score(model.predict(data[i][0]), data[i][1])\n",
    "        scores[split] = metrics\n",
    "    return scores\n",
    "\n",
    "\n",
    "def scores_to_df(scores, verbose=True):\n",
    "    scores_df = pd.DataFrame(scores)\n",
    "    scores_df[\"difference\"] = scores_df[\"train\"] - scores_df[\"val\"]\n",
    "    if verbose:\n",
    "        print(\"---- BEST SCORES ---\")\n",
    "        print(scores_df)\n",
    "    return scores_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b4b7ec-a38c-4d21-aa0c-0612e45a5c82",
   "metadata": {
    "papermill": {
     "duration": 0.026899,
     "end_time": "2022-02-06T21:07:08.701316",
     "exception": false,
     "start_time": "2022-02-06T21:07:08.674417",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### FITTERS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fd0f2d3-111f-427a-aa53-3331fc52e078",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T21:07:08.760982Z",
     "iopub.status.busy": "2022-02-06T21:07:08.760548Z",
     "iopub.status.idle": "2022-02-06T21:07:08.762726Z",
     "shell.execute_reply": "2022-02-06T21:07:08.762373Z"
    },
    "papermill": {
     "duration": 0.033734,
     "end_time": "2022-02-06T21:07:08.762850",
     "exception": false,
     "start_time": "2022-02-06T21:07:08.729116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_results(model, data):\n",
    "    # PRINT BEST RESULTS ------\n",
    "    scores = score_model(model, data)\n",
    "    scores_df = scores_to_df(scores)\n",
    "\n",
    "    best_params = model.get_params()\n",
    "    printmd(md(f\"Paramètres du modèle: {best_params}\"))\n",
    "    return scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3725046-58c1-4ca2-90c9-1be796b02bf9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T21:07:08.828045Z",
     "iopub.status.busy": "2022-02-06T21:07:08.827380Z",
     "iopub.status.idle": "2022-02-06T21:07:08.829542Z",
     "shell.execute_reply": "2022-02-06T21:07:08.828996Z"
    },
    "papermill": {
     "duration": 0.037528,
     "end_time": "2022-02-06T21:07:08.829703",
     "exception": false,
     "start_time": "2022-02-06T21:07:08.792175",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit_baseline_model(trainer, data, pass_val=False, params=False, **kwargs):\n",
    "    # --- --- --- BASELINE --- --- ---\n",
    "    kind = \"baseline\"\n",
    "\n",
    "    # * Fit if requested ---\n",
    "    if pass_val and params:\n",
    "        model = trainer(params, data, best_params=None)\n",
    "    else:\n",
    "        model = trainer((data[0][0], data[0][1]), best_params=None)\n",
    "\n",
    "    # Best rmsle ---\n",
    "    best_score = rmsle(estimator=model, X=data[1][0], y_true=data[1][1])\n",
    "\n",
    "    return (model, kind, best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f7193dc1-5e9c-4890-a2fb-550048092ca8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T21:07:08.897960Z",
     "iopub.status.busy": "2022-02-06T21:07:08.897403Z",
     "iopub.status.idle": "2022-02-06T21:07:08.898781Z",
     "shell.execute_reply": "2022-02-06T21:07:08.899245Z"
    },
    "papermill": {
     "duration": 0.037467,
     "end_time": "2022-02-06T21:07:08.899424",
     "exception": false,
     "start_time": "2022-02-06T21:07:08.861957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def fit_grid_model(\n",
    "    trainer,\n",
    "    data,\n",
    "    grid_params,\n",
    "    grid_search_kwargs,\n",
    "    pass_val=False,\n",
    "    params=False,\n",
    "    verbose=True,\n",
    "):\n",
    "    # --- --- --- BASELINE --- --- ---\n",
    "    kind = \"grid\"\n",
    "\n",
    "    if params:\n",
    "        # * Init instance ---\n",
    "        model = trainer(params=params)\n",
    "    else:\n",
    "        model = trainer()\n",
    "\n",
    "    # * GridSearchCV ---\n",
    "    search = GridSearchCV(model, param_grid=grid_params, **grid_search_kwargs)\n",
    "\n",
    "    # * Fit if requested ---\n",
    "    if pass_val:\n",
    "        search.fit(\n",
    "            data[0][0],\n",
    "            data[0][1],\n",
    "            eval_set=[data[1]],  # Validation set for early stopping\n",
    "            early_stopping_rounds=15,\n",
    "            verbose=0,\n",
    "        )\n",
    "    else:\n",
    "        search.fit(data[0][0], data[0][1])\n",
    "\n",
    "    # PRINT BEST RESULTS ------\n",
    "    if verbose:\n",
    "        best_score = search.best_score_\n",
    "        printmd(\n",
    "            md(\n",
    "                f\"Le meilleur score obtenu par notre grid search (à savoir, le score est le RMSLE): {best_score}\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        best_params = search.best_params_\n",
    "        printmd(md(f\"Le meilleurs paramètres: {best_params}\"))\n",
    "\n",
    "    return search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99a13e88-d427-4cd6-b689-3d9eedbcc3b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T21:07:08.960782Z",
     "iopub.status.busy": "2022-02-06T21:07:08.960453Z",
     "iopub.status.idle": "2022-02-06T21:07:08.961754Z",
     "shell.execute_reply": "2022-02-06T21:07:08.961450Z"
    },
    "papermill": {
     "duration": 0.031585,
     "end_time": "2022-02-06T21:07:08.961839",
     "exception": false,
     "start_time": "2022-02-06T21:07:08.930254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def refit_with_params(trainer, best_params, data, pass_val=False):\n",
    "    # * Fit if requested ---\n",
    "    if pass_val and params:\n",
    "        model = trainer(params, data, best_params=best_params)\n",
    "    else:\n",
    "        model = trainer((data[0][0], data[0][1]), best_params=best_params)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0014db5-9140-43bf-824b-3023a0aa4f80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T21:07:09.024198Z",
     "iopub.status.busy": "2022-02-06T21:07:09.023666Z",
     "iopub.status.idle": "2022-02-06T21:07:09.025543Z",
     "shell.execute_reply": "2022-02-06T21:07:09.026020Z"
    },
    "papermill": {
     "duration": 0.036601,
     "end_time": "2022-02-06T21:07:09.026197",
     "exception": false,
     "start_time": "2022-02-06T21:07:08.989596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def refit_with_selection(\n",
    "    trainer,\n",
    "    data,\n",
    "    model_with_importances,\n",
    "    all_cols,\n",
    "    grid_params,\n",
    "    grid_search_kwargs,\n",
    "    pass_val,\n",
    "    params,\n",
    "    best_params,\n",
    "    th=0.001,\n",
    "    verbose=False,\n",
    "):\n",
    "    # which features ---\n",
    "    subset = model_with_importances.feature_importances_ > th\n",
    "    important_cols = all_cols[subset].tolist()\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"IMPORTANT COLUMNS KEPT FOR RETRAINING {important_cols}\")\n",
    "\n",
    "    data_th = [(data[0][0][:, subset], data[0][1]), (data[1][0][:, subset], data[1][1])]\n",
    "    search = fit_grid_model(\n",
    "        trainer, data_th, grid_params, grid_search_kwargs, pass_val, params, verbose\n",
    "    )\n",
    "\n",
    "    model = refit_with_params(\n",
    "        trainer, search.best_params_, data=data_th, pass_val=pass_val\n",
    "    )\n",
    "\n",
    "    best_score = search.best_score_\n",
    "    return model, important_cols, subset, best_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cebb1be4-f292-49ad-87e6-6860926cc874",
   "metadata": {
    "papermill": {
     "duration": 0.026868,
     "end_time": "2022-02-06T21:07:09.085477",
     "exception": false,
     "start_time": "2022-02-06T21:07:09.058609",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Data Paths "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b54d143-6978-426a-bc89-6b54855a3959",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T21:07:09.145803Z",
     "iopub.status.busy": "2022-02-06T21:07:09.142414Z",
     "iopub.status.idle": "2022-02-06T21:07:09.147151Z",
     "shell.execute_reply": "2022-02-06T21:07:09.147397Z"
    },
    "papermill": {
     "duration": 0.034322,
     "end_time": "2022-02-06T21:07:09.147508",
     "exception": false,
     "start_time": "2022-02-06T21:07:09.113186",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- --- --- FOLDERS AND FILES --- --- ---\n",
    "# * Data path ---\n",
    "data_path = os.path.join(base_path, \"data\")\n",
    "\n",
    "# * House dataset paths ---\n",
    "house_train = os.path.join(data_path, \"house\", \"train.csv\")\n",
    "\n",
    "# * Bills dataset paths ---\n",
    "bill_train = os.path.join(data_path, \"bills\",\"bill_authentication.csv\")\n",
    "\n",
    "# * Wine dataset paths ---\n",
    "wine_train = os.path.join(data_path, \"wine\",\"winequality-red.csv\")\n",
    "\n",
    "# init scaler\n",
    "scaler_name = None\n",
    "Preprocess = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89367d19-0135-47d5-95cc-c3421fc8c756",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T21:07:09.208318Z",
     "iopub.status.busy": "2022-02-06T21:07:09.207627Z",
     "iopub.status.idle": "2022-02-06T21:07:09.209002Z",
     "shell.execute_reply": "2022-02-06T21:07:09.209522Z"
    },
    "papermill": {
     "duration": 0.033805,
     "end_time": "2022-02-06T21:07:09.209718",
     "exception": false,
     "start_time": "2022-02-06T21:07:09.175913",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# --- --- --- MODEL FITTING PARAMETERS --- --- ---\n",
    "\n",
    "# FIT OR LOAD MODEL ------\n",
    "toFitXGB = True\n",
    "toFitRF = True\n",
    "toFitSVM = True\n",
    "toFitMLP = True\n",
    "\n",
    "# * Fitting options ---\n",
    "toScale = True\n",
    "\n",
    "# *Handle categorical vars\n",
    "categorical = True\n",
    "\n",
    "# DEFAULT STORAGE PARAMETERS ------\n",
    "to_rm_storage = True\n",
    "### DATA PARAMETERS ---\n",
    "training_data_path = None\n",
    "dataset = None\n",
    "dependent = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f227b0b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T21:07:09.271278Z",
     "iopub.status.busy": "2022-02-06T21:07:09.270924Z",
     "iopub.status.idle": "2022-02-06T21:07:09.272731Z",
     "shell.execute_reply": "2022-02-06T21:07:09.272421Z"
    },
    "papermill": {
     "duration": 0.032333,
     "end_time": "2022-02-06T21:07:09.272823",
     "exception": false,
     "start_time": "2022-02-06T21:07:09.240490",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "to_rm_storage = False\n",
    "training_data_path = \"wine_train\"\n",
    "dataset = \"bill\"\n",
    "dependent = \"Class\"\n",
    "categorical = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d08150bd-62a2-4d80-b7ca-a8fc033670ad",
   "metadata": {
    "papermill": {
     "duration": 0.027272,
     "end_time": "2022-02-06T21:07:09.327656",
     "exception": false,
     "start_time": "2022-02-06T21:07:09.300384",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Folders "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fb1da5e-e78e-49b4-817d-baff9ff2516d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T21:07:09.388682Z",
     "iopub.status.busy": "2022-02-06T21:07:09.388347Z",
     "iopub.status.idle": "2022-02-06T21:07:09.391310Z",
     "shell.execute_reply": "2022-02-06T21:07:09.391028Z"
    },
    "papermill": {
     "duration": 0.035665,
     "end_time": "2022-02-06T21:07:09.391447",
     "exception": false,
     "start_time": "2022-02-06T21:07:09.355782",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 520 µs, sys: 354 µs, total: 874 µs\n",
      "Wall time: 663 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# FOLDERS TO STORE ------\n",
    "paths_to_create = [\n",
    "    os.path.join(base_path, \"scale_dump\"),\n",
    "    os.path.join(base_path, \"model_dump\"),\n",
    "    os.path.join(base_path, \"grid_search\"),\n",
    "]\n",
    "\n",
    "# REMOVE PREVIOUS STORAGE IF NEEDED ------\n",
    "if to_rm_storage:\n",
    "    print(\"--- Removing previous saved models, grids and scalers ---\")\n",
    "    for folder in paths_to_create:\n",
    "        shutil.rmtree(folder, ignore_errors=True)\n",
    "\n",
    "# (RE)CREATE STORAGE FOLDERS ------\n",
    "for folder in paths_to_create:\n",
    "    os.makedirs(folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7a80e7-c61c-4a9e-8b64-61e04f23457b",
   "metadata": {
    "papermill": {
     "duration": 0.028707,
     "end_time": "2022-02-06T21:07:09.460547",
     "exception": false,
     "start_time": "2022-02-06T21:07:09.431840",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## MODEL PARAMETERS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4888bc90-804c-4e00-b3e8-466dc5deff71",
   "metadata": {
    "papermill": {
     "duration": 0.030048,
     "end_time": "2022-02-06T21:07:09.518683",
     "exception": false,
     "start_time": "2022-02-06T21:07:09.488635",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### MODEL PARAMETERS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac1206c0-cd17-41cd-b76e-339f1698abe2",
   "metadata": {
    "papermill": {
     "duration": 0.027486,
     "end_time": "2022-02-06T21:07:09.574282",
     "exception": false,
     "start_time": "2022-02-06T21:07:09.546796",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "265249ef-80a6-4525-9773-1595ddf85459",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T21:07:09.636032Z",
     "iopub.status.busy": "2022-02-06T21:07:09.635701Z",
     "iopub.status.idle": "2022-02-06T21:07:09.638248Z",
     "shell.execute_reply": "2022-02-06T21:07:09.638601Z"
    },
    "papermill": {
     "duration": 0.036313,
     "end_time": "2022-02-06T21:07:09.638747",
     "exception": false,
     "start_time": "2022-02-06T21:07:09.602434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPUS DETECTED : 12\n",
      "CPUS TO USE : 9\n"
     ]
    }
   ],
   "source": [
    "# Multiprocessing ---\n",
    "cpus = multiprocessing.cpu_count()\n",
    "cpu_ratio = 0.8\n",
    "cpus_to_use = int(cpus * cpu_ratio)\n",
    "print(f\"CPUS DETECTED : {cpus}\")\n",
    "print(f\"CPUS TO USE : {cpus_to_use}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c93f4c-c461-4387-abfb-9062fe687a3b",
   "metadata": {
    "papermill": {
     "duration": 0.02753,
     "end_time": "2022-02-06T21:07:09.693801",
     "exception": false,
     "start_time": "2022-02-06T21:07:09.666271",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### CV PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d36cee3-2623-4300-8b83-9520ff00fb99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T21:07:09.755260Z",
     "iopub.status.busy": "2022-02-06T21:07:09.754933Z",
     "iopub.status.idle": "2022-02-06T21:07:09.756432Z",
     "shell.execute_reply": "2022-02-06T21:07:09.756689Z"
    },
    "papermill": {
     "duration": 0.034575,
     "end_time": "2022-02-06T21:07:09.756797",
     "exception": false,
     "start_time": "2022-02-06T21:07:09.722222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- --- --- CV PARAMS --- --- ---\n",
    "folds = 3\n",
    "rstate = 123\n",
    "\n",
    "# * K Fold ---\n",
    "skf = KFold(n_splits=folds, shuffle=True, random_state=rstate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "77fa33b4-9378-4a0c-9b00-b5277aa25d4c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T21:07:09.815704Z",
     "iopub.status.busy": "2022-02-06T21:07:09.815359Z",
     "iopub.status.idle": "2022-02-06T21:07:09.817160Z",
     "shell.execute_reply": "2022-02-06T21:07:09.817579Z"
    },
    "papermill": {
     "duration": 0.033262,
     "end_time": "2022-02-06T21:07:09.817724",
     "exception": false,
     "start_time": "2022-02-06T21:07:09.784462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- --- --- XGB HYPER PARAMS --- --- ---\n",
    "# * Grid for xgb ---\n",
    "xgb_params = {\n",
    "    \"min_child_weight\": [1, 5, 10],\n",
    "    \"gamma\": [0.001, 0.02, 0.04, 0.08, 0.1, 0.5],\n",
    "    \"subsample\": [0.6, 0.8, 1.0],\n",
    "    \"colsample_bytree\": [0.6, 0.8, 1.0],\n",
    "    \"max_depth\": [1, 2, 4, 5],\n",
    "    \"lambda\": [0, 0.01, 0.02, 0.5, 1],  # no much pbs of overfting\n",
    "}\n",
    "objective = \"reg:squaredlogerror\"  # metric RMSLE\n",
    "objective = \"reg:squarederror\"  # RMSLE STUCKED ...\n",
    "metric = \"mae\"\n",
    "rmsle = rmsle_scorer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "41b98e16-0c9a-4fae-9eab-2eb1281c43ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T21:07:09.899263Z",
     "iopub.status.busy": "2022-02-06T21:07:09.898928Z",
     "iopub.status.idle": "2022-02-06T21:07:09.900902Z",
     "shell.execute_reply": "2022-02-06T21:07:09.901186Z"
    },
    "papermill": {
     "duration": 0.054217,
     "end_time": "2022-02-06T21:07:09.901296",
     "exception": false,
     "start_time": "2022-02-06T21:07:09.847079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Original Number of combinations : 5474\n",
      "RF Number of correct combinations : 912\n"
     ]
    }
   ],
   "source": [
    "# --- --- --- RANDOM FOREST HYPER PARAMS --- --- ---\n",
    "max_depth_val = 18\n",
    "max_depth = np.arange(1, max_depth_val, 1)\n",
    "max_leaf_nodes = np.arange(\n",
    "    2, max_depth_val * max_depth_val, 1\n",
    ")  # si on ajoute un max_depth x il faut au plus accepter x*x feuilles...\n",
    "\n",
    "params_combinations = list(product(max_depth, max_leaf_nodes))\n",
    "print(\"RF Original Number of combinations : %s\" % len(params_combinations))\n",
    "\n",
    "# REMOVE ILOGIC COMBINATIONS cf.TP2 ------\n",
    "correct_params = []\n",
    "incorrect_params = []\n",
    "for depth, leaves in params_combinations:\n",
    "    max_feuilles = depth * depth\n",
    "    if leaves > max_feuilles or leaves < np.round(0.5 * max_feuilles):  # critères\n",
    "        incorrect_params.append((depth, leaves))\n",
    "    else:\n",
    "        correct_params.append((depth, leaves))\n",
    "\n",
    "rf_params = []\n",
    "for depth, leaves in correct_params:\n",
    "    grille = {\n",
    "        \"max_depth\": [depth],  # wrap in one list element\n",
    "        \"max_leaf_nodes\": [leaves],\n",
    "    }\n",
    "    rf_params.append(grille)\n",
    "\n",
    "print(\"RF Number of correct combinations : %s\" % len(correct_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee02bc68-6f18-4bca-8eee-62c2a2debd92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T21:07:09.964002Z",
     "iopub.status.busy": "2022-02-06T21:07:09.963551Z",
     "iopub.status.idle": "2022-02-06T21:07:09.965201Z",
     "shell.execute_reply": "2022-02-06T21:07:09.965444Z"
    },
    "papermill": {
     "duration": 0.035858,
     "end_time": "2022-02-06T21:07:09.965552",
     "exception": false,
     "start_time": "2022-02-06T21:07:09.929694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- --- --- SVM HYPER PARAMS --- --- ---\n",
    "\n",
    "# possibilities ---\n",
    "Cs = np.linspace(0.5, 40, 7)\n",
    "KERNELS = [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]\n",
    "# grid ---\n",
    "svm_params = {\"C\": Cs, \"kernel\": KERNELS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd1466d7-326b-453a-8e2d-54d7e32545ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T21:07:10.026277Z",
     "iopub.status.busy": "2022-02-06T21:07:10.025946Z",
     "iopub.status.idle": "2022-02-06T21:07:10.029024Z",
     "shell.execute_reply": "2022-02-06T21:07:10.028633Z"
    },
    "papermill": {
     "duration": 0.034514,
     "end_time": "2022-02-06T21:07:10.029134",
     "exception": false,
     "start_time": "2022-02-06T21:07:09.994620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --- --- --- MLP HYPER PARAMS --- --- ---\n",
    "\n",
    "mlp_params = {\n",
    "    \"hidden_layer_sizes\": [(50, 50, 50), (50, 100, 50), (100,)],\n",
    "    \"activation\": [\"tanh\", \"relu\"],\n",
    "    \"solver\": [\"sgd\", \"adam\"],\n",
    "    \"alpha\": [0.0001, 0.05],\n",
    "    \"learning_rate\": [\"constant\", \"adaptive\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc8463b-ca71-45ac-a2e7-3df3ae727757",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "papermill": {
     "duration": 0.027859,
     "end_time": "2022-02-06T21:07:10.086475",
     "exception": false,
     "start_time": "2022-02-06T21:07:10.058616",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## IMPORT DATA "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f915346b-977c-433d-8ab2-a5a234fd3555",
   "metadata": {
    "papermill": {
     "duration": 0.028784,
     "end_time": "2022-02-06T21:07:10.145803",
     "exception": false,
     "start_time": "2022-02-06T21:07:10.117019",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### House "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9efbacad-e9ef-4dbd-97e9-a357ee536079",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T21:07:10.212080Z",
     "iopub.status.busy": "2022-02-06T21:07:10.210179Z",
     "iopub.status.idle": "2022-02-06T21:07:12.414479Z",
     "shell.execute_reply": "2022-02-06T21:07:12.415040Z"
    },
    "papermill": {
     "duration": 2.240876,
     "end_time": "2022-02-06T21:07:12.415250",
     "exception": false,
     "start_time": "2022-02-06T21:07:10.174374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['Class'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:13\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mpreprocess_data_as_model\u001b[0;34m(data, dependent, categorical)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_data_as_model\u001b[39m(data, dependent, categorical):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# * Divide X,y ---\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     data_subset \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdependent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     y \u001b[38;5;241m=\u001b[39m data[dependent]\u001b[38;5;241m.\u001b[39mvalues\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# handle categorical variables ---\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/frame.py:4956\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4808\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   4809\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   4810\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4817\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   4818\u001b[0m ):\n\u001b[1;32m   4819\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4820\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   4821\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4954\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   4955\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4956\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4958\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4959\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4960\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4961\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4962\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4963\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4964\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/generic.py:4279\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4277\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4278\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4279\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4282\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/generic.py:4323\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[1;32m   4321\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4323\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4324\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4326\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4327\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/pandas/core/indexes/base.py:6644\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6643\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 6644\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6645\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   6646\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['Class'] not found in axis\""
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# --- --- --- DATA --- --- ---\n",
    "# * Load data ---\n",
    "data = pd.read_csv(eval(training_data_path), sep=\",\")\n",
    "\n",
    "(\n",
    "    data_subset,\n",
    "    y,\n",
    "    all_cols,\n",
    "    numeric_cols,\n",
    "    numeric_cols_index,\n",
    "    categorical_cols,\n",
    "    categorical_cols_index,\n",
    ") = preprocess_data_as_model(data, dependent, categorical)\n",
    "cols_beginning = data_subset.columns.values\n",
    "\n",
    "# DEFINE TRANSFORMATION BASED ON OPTIONS ------\n",
    "# Transformations ---\n",
    "transformations = []\n",
    "if categorical:\n",
    "    # One hot encoder ---\n",
    "    encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "    transformer = (\"cat_cols\", encoder, categorical_cols_index)  # on cat cols\n",
    "    transformations.append(transformer)\n",
    "\n",
    "else:\n",
    "    # Training cols ---\n",
    "    data_subset = data_subset.select_dtypes([\"number\"])  # drop categorical\n",
    "    all_cols = cols_beginning[numeric_cols_index]  # only numerical cols ....\n",
    "    numeric_cols_index = (\n",
    "        data_subset.columns.values != None\n",
    "    )  # apply transformation to all columns\n",
    "\n",
    "\n",
    "# * Optional Scaling ---\n",
    "if toScale:\n",
    "    # unit variance scaler ---\n",
    "    scaler = StandardScaler()\n",
    "    transformer = (\"num_cols\", scaler, numeric_cols_index)  # on num cols\n",
    "    transformations.append(transformer)\n",
    "\n",
    "# * TRAIN VAL TEST SPLIT ---\n",
    "# train test\n",
    "X_train, XHold_test, y_train, yHold_test = train_test_split(\n",
    "    data_subset.values, y, test_size=0.15, random_state=rstate\n",
    ")\n",
    "# train validation\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(\n",
    "    X_train, y_train, test_size=0.15, random_state=rstate\n",
    ")\n",
    "\n",
    "#\n",
    "\n",
    "if toScale or categorical:\n",
    "    print(\n",
    "        f\"--- Column Transformation. Scaling:{toScale} , OneHotEncoder : {categorical}  ---\"\n",
    "    )\n",
    "    Preprocess = ColumnTransformer(\n",
    "        transformations, n_jobs=cpus_to_use, remainder=\"passthrough\"\n",
    "    )\n",
    "    # fit ---\n",
    "    X_train = Preprocess.fit_transform(X_train)\n",
    "    X_validation = Preprocess.transform(X_validation)\n",
    "    XHold_test = Preprocess.transform(XHold_test)\n",
    "\n",
    "    # get names ---\n",
    "    all_cols = Preprocess.get_feature_names_out()\n",
    "\n",
    "    # dump to reuse\n",
    "    scaler_name = f\"scale_dump/ColumnTransformer_{dataset}_{init_time}.pkl\"\n",
    "    dump(Preprocess, open(scaler_name, \"wb\"))\n",
    "\n",
    "# TRAIN VAL TEST SPLIT ------\n",
    "data_splits = [\n",
    "    (X_train, y_train),\n",
    "    (X_validation, y_validation),\n",
    "    (XHold_test, yHold_test),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "be860d2a-1571-4c8f-b5a9-2bd5e978e33e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T21:07:12.484002Z",
     "iopub.status.busy": "2022-02-06T21:07:12.483355Z",
     "iopub.status.idle": "2022-02-06T21:07:12.484678Z",
     "shell.execute_reply": "2022-02-06T21:07:12.485195Z"
    },
    "papermill": {
     "duration": 0.034413,
     "end_time": "2022-02-06T21:07:12.485388",
     "exception": false,
     "start_time": "2022-02-06T21:07:12.450975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid_search_kwargs = dict(\n",
    "    scoring=rmsle, n_jobs=cpus_to_use, refit=True, cv=skf, verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed03a8c9-7c6d-4674-a2bd-4be6f7317e27",
   "metadata": {
    "papermill": {
     "duration": 0.028224,
     "end_time": "2022-02-06T21:07:12.550350",
     "exception": false,
     "start_time": "2022-02-06T21:07:12.522126",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## XGBOOST "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433002c9",
   "metadata": {
    "tags": [
     "papermill-error-cell-tag"
    ]
   },
   "source": [
    "<span id=\"papermill-error-cell\" style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">Execution using papermill encountered an exception here and stopped:</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b31cdf5c-e1e8-4709-98c5-7d96bd7f8a17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-06T21:07:12.615582Z",
     "iopub.status.busy": "2022-02-06T21:07:12.615200Z",
     "iopub.status.idle": "2022-02-06T21:07:12.908728Z",
     "shell.execute_reply": "2022-02-06T21:07:12.908074Z"
    },
    "papermill": {
     "duration": 0.32955,
     "end_time": "2022-02-06T21:07:12.909051",
     "exception": true,
     "start_time": "2022-02-06T21:07:12.579501",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_cols' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [25]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m saver_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m      2\u001b[0m     dataset\u001b[38;5;241m=\u001b[39mdataset,\n\u001b[1;32m      3\u001b[0m     model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxgb\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     objective\u001b[38;5;241m=\u001b[39mobjective,\n\u001b[1;32m      5\u001b[0m     toScale\u001b[38;5;241m=\u001b[39mtoScale,\n\u001b[1;32m      6\u001b[0m     init_time\u001b[38;5;241m=\u001b[39minit_time,\n\u001b[0;32m----> 7\u001b[0m     columns_used\u001b[38;5;241m=\u001b[39m\u001b[43mall_cols\u001b[49m,\n\u001b[1;32m      8\u001b[0m     Preprocess\u001b[38;5;241m=\u001b[39mPreprocess,\n\u001b[1;32m      9\u001b[0m     preprocessing_path\u001b[38;5;241m=\u001b[39mscaler_name,\n\u001b[1;32m     10\u001b[0m     categorical\u001b[38;5;241m=\u001b[39mcategorical,\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m saver_grid_params \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     21\u001b[0m ]:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'all_cols' is not defined"
     ]
    }
   ],
   "source": [
    "saver_params = dict(\n",
    "    dataset=dataset,\n",
    "    model_name=\"xgb\",\n",
    "    objective=objective,\n",
    "    toScale=toScale,\n",
    "    init_time=init_time,\n",
    "    columns_used=all_cols,\n",
    "    Preprocess=Preprocess,\n",
    "    preprocessing_path=scaler_name,\n",
    "    categorical=categorical,\n",
    ")\n",
    "\n",
    "saver_grid_params = {}\n",
    "for i in [\n",
    "    \"model_name\",\n",
    "    \"dataset\",\n",
    "    \"init_time\",\n",
    "    \"preprocessing_path\",\n",
    "    \"toScale\",\n",
    "    \"categorical\",\n",
    "]:\n",
    "    saver_grid_params[i] = saver_params.get(i)\n",
    "\n",
    "params = {\n",
    "    \"objective\": objective,\n",
    "    \"learning_rate\": 0.02,\n",
    "    \"n_estimators\": 700,\n",
    "    \"n_jobs\": 1,  # if not defaults to -1...\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4faa5f84-83b9-4c90-892c-f10422123b66",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### BASIC MODEL (NO HPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501cb85c-62ca-4c35-a8f1-a931c38caa35",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# --- --- --- XGBOOST --- --- ---\n",
    "if toFitXGB:\n",
    "    model, kind, best_score = fit_baseline_model(\n",
    "        train_xgb_classification,\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        pass_val=True,\n",
    "        params=params,\n",
    "    )\n",
    "\n",
    "    scores_df = get_results(model, data_splits)\n",
    "    # SAVE RESULTS ------\n",
    "    save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )\n",
    "    # boost.get_booster().feature_names= important_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729e4e95-b6e4-4fd5-89e0-f7d05ca2450f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37755148-2fa9-464f-a20d-6c209325bef5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# --- --- --- XGBOOST GRID SEARCH --- --- ---\n",
    "if toFitXGB:\n",
    "    kind = \"grid\"\n",
    "\n",
    "    search = fit_grid_model(\n",
    "        train_xgb_classification,\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        grid_params=xgb_params,\n",
    "        grid_search_kwargs=grid_search_kwargs,\n",
    "        pass_val=True,\n",
    "        params=params,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # REFIT TO GET TRAINING ERROR AT EACH STEP ------\n",
    "\n",
    "    model = refit_with_params(\n",
    "        train_xgb_classification,\n",
    "        search.best_estimator_.get_xgb_params(),\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        pass_val=True,\n",
    "    )\n",
    "    # Score model ---\n",
    "    scores_df = get_results(model, data_splits)\n",
    "    best_score = search.best_score_\n",
    "    # Save model ---\n",
    "    model_path = save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )\n",
    "    # Save grid search results ---\n",
    "    save_grid(model_path=model_path, search=search, **saver_grid_params)\n",
    "    # boost.get_booster().feature_names= important_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c0b82c-7cb2-4898-baab-f916b1766e6d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Refit on feature selection "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9486b96-a180-47ca-8e50-54bfae922f10",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if toFitXGB:\n",
    "    model, important_cols, subset, best_score = refit_with_selection(\n",
    "        train_xgb_classification,\n",
    "        [(X_train, y_train), (X_validation, y_validation)],\n",
    "        model_with_importances=model,\n",
    "        all_cols=all_cols,\n",
    "        grid_params=xgb_params,\n",
    "        grid_search_kwargs=grid_search_kwargs,\n",
    "        pass_val=True,\n",
    "        params=params,\n",
    "        best_params=search.best_estimator_.get_xgb_params(),\n",
    "        th=0.001,\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    model.get_booster().feature_names = important_cols\n",
    "\n",
    "    data_splits_th = [\n",
    "        (data_splits[0][0][:, subset], data_splits[0][1]),\n",
    "        (data_splits[1][0][:, subset], data_splits[1][1]),\n",
    "        (data_splits[2][0][:, subset], data_splits[2][1]),\n",
    "    ]\n",
    "\n",
    "    scores_df = get_results(model, data_splits_th)\n",
    "    # Save model ---\n",
    "    kind = \"refit\"\n",
    "    model_path = save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92dc3d7-6238-447e-81e5-44d0863987f7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## RF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4c47ec-7d1d-40be-ba9d-00db2bf58dc2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# * Split for learning ---\n",
    "# train test\n",
    "if toFitRF or toFitMLP or toFitSVM:\n",
    "\n",
    "    X_train, XHold_test, y_train, yHold_test = train_test_split(\n",
    "        data_subset.values, y, test_size=0.15, random_state=rstate\n",
    "    )\n",
    "    # train validation\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(\n",
    "        X_train, y_train, test_size=0.15, random_state=rstate\n",
    "    )\n",
    "\n",
    "    knnI = KNNImputer()\n",
    "    #\n",
    "    if toScale or categorical:\n",
    "        print(\n",
    "            f\"--- Column Transformation. Scaling:{toScale} , OneHotEncoder : {categorical}, Imputer : knnImputer  ---\"\n",
    "        )\n",
    "        Preprocess = ColumnTransformer(\n",
    "            transformations, n_jobs=cpus_to_use, remainder=\"passthrough\"\n",
    "        )\n",
    "\n",
    "        Preprocess = Pipeline([(\"col_trans\", Preprocess), (\"imputer\", knnI)])\n",
    "    else:\n",
    "        Preprocess = Pipeline([(\"imputer\", knnI)])\n",
    "\n",
    "    # fit ---\n",
    "    Preprocess.fit(X_train)\n",
    "    X_train = Preprocess.transform(X_train)\n",
    "    X_validation = Preprocess.transform(X_validation)\n",
    "    XHold_test = Preprocess.transform(XHold_test)\n",
    "\n",
    "    # get names ---\n",
    "    if toScale or categorical:\n",
    "\n",
    "        all_cols = Preprocess[0].get_feature_names_out()\n",
    "\n",
    "    # dump to reuse\n",
    "    preprocessing_name = f\"scale_dump/ColumnTransformer__rf_{init_time}.pkl\"\n",
    "    dump(Preprocess, open(preprocessing_name, \"wb\"))\n",
    "\n",
    "# TRAIN VAL TEST SPLIT ------\n",
    "data_splits = [\n",
    "    (X_train, y_train),\n",
    "    (X_validation, y_validation),\n",
    "    (XHold_test, yHold_test),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a48298-3ca5-4168-bc0a-d9fceda01119",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### BASIC MODEL (NO HPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa7e26e-bda0-4988-b044-ff6a03618153",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "saver_params = dict(\n",
    "    dataset=dataset,\n",
    "    model_name=\"rf\",\n",
    "    objective=\"squared_error\",\n",
    "    toScale=toScale,\n",
    "    init_time=init_time,\n",
    "    columns_used=all_cols,\n",
    "    Preprocess=Preprocess,\n",
    "    preprocessing_path=scaler_name,\n",
    "    categorical=categorical,\n",
    ")\n",
    "# --- --- --- BASELINE RF --- --- ---\n",
    "if toFitRF:\n",
    "    model, kind, best_score = fit_baseline_model(\n",
    "        train_rf_classification,\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        pass_val=False,\n",
    "        params=None,\n",
    "    )\n",
    "\n",
    "    scores_df = get_results(model, data_splits)\n",
    "    # SAVE RESULTS ------\n",
    "    save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433b924e-9efc-4b18-b162-3b48458cd99b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5305496-c1c7-4ee3-8428-aed5ea0528f7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# --- --- --- RF GRID SEARCH --- --- ---\n",
    "if toFitRF:\n",
    "    kind = \"grid\"\n",
    "\n",
    "    search = fit_grid_model(\n",
    "        train_rf_classification,\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        grid_params=rf_params,\n",
    "        grid_search_kwargs=grid_search_kwargs,\n",
    "        pass_val=False,\n",
    "        params=None,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # REFIT TO GET TRAINING ERROR AT EACH STEP ------\n",
    "\n",
    "    model = refit_with_params(\n",
    "        train_rf_classification,\n",
    "        search.best_params_,\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        pass_val=False,\n",
    "    )\n",
    "    # Score model ---\n",
    "    scores_df = get_results(model, data_splits)\n",
    "    best_score = search.best_score_\n",
    "    # Save model ---\n",
    "    model_path = save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )\n",
    "    # Save grid search results ---\n",
    "    save_grid(model_path=model_path, search=search, **saver_grid_params)\n",
    "    # boost.get_booster().feature_names= important_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de5fa8a-f551-4a9e-bfe3-18270ce751e8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### REFIT on subsample of cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864224a8-aa00-41d0-af17-605eefc1fcf4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if toFitRF:\n",
    "    model, important_cols, subset, best_score = refit_with_selection(\n",
    "        train_rf_classification,\n",
    "        [(X_train, y_train), (X_validation, y_validation)],\n",
    "        model_with_importances=model,\n",
    "        all_cols=all_cols,\n",
    "        grid_params=rf_params,\n",
    "        grid_search_kwargs=grid_search_kwargs,\n",
    "        pass_val=False,\n",
    "        params=None,\n",
    "        best_params=search.best_params_,\n",
    "        th=0.001,\n",
    "        verbose=False,\n",
    "    )\n",
    "    data_splits_th = [\n",
    "        (data_splits[0][0][:, subset], data_splits[0][1]),\n",
    "        (data_splits[1][0][:, subset], data_splits[1][1]),\n",
    "        (data_splits[2][0][:, subset], data_splits[2][1]),\n",
    "    ]\n",
    "\n",
    "    scores_df = get_results(model, data_splits_th)\n",
    "    # Save model ---\n",
    "    kind = \"refit\"\n",
    "    model_path = save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )\n",
    "    # Save grid search results ---\n",
    "    # save_grid(model_path=model_path, search=search, **saver_grid_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5064110c-cb60-4d11-bd26-af84038d9aba",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## SVM "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db58ca93-29a5-4e9a-88d0-732c8a9b8d95",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### BASELINE SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7ebe1e-12b5-4dd8-aec0-49a892bcdefb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "saver_params = dict(\n",
    "    dataset=dataset,\n",
    "    model_name=\"svm\",\n",
    "    objective=\"misclassification\",\n",
    "    toScale=toScale,\n",
    "    init_time=init_time,\n",
    "    columns_used=all_cols,\n",
    "    Preprocess=Preprocess,\n",
    "    preprocessing_path=scaler_name,\n",
    "    categorical=categorical,\n",
    ")\n",
    "\n",
    "# --- --- --- BASELINE RF --- --- ---\n",
    "if toFitSVM:\n",
    "    model, kind, best_score = fit_baseline_model(\n",
    "        train_svr_classification,\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        pass_val=False,\n",
    "        params=None,\n",
    "    )\n",
    "\n",
    "    scores_df = get_results(model, data_splits)\n",
    "    # SAVE RESULTS ------\n",
    "    save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720fc626-861a-4983-8799-7a52a503670a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4e53fb-2e8c-43a3-b886-f455cadf3fbe",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# --- --- --- SVM GRID SEARCH --- --- ---\n",
    "if toFitSVM:\n",
    "    kind = \"grid\"\n",
    "\n",
    "    search = fit_grid_model(\n",
    "        train_svr_classification,\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        grid_params=svm_params,\n",
    "        grid_search_kwargs=grid_search_kwargs,\n",
    "        pass_val=False,\n",
    "        params=None,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # REFIT TO GET TRAINING ERROR AT EACH STEP ------\n",
    "\n",
    "    model = search.best_estimator_\n",
    "    # Score model ---\n",
    "    scores_df = get_results(model, data_splits)\n",
    "    best_score = search.best_score_\n",
    "    # Save model ---\n",
    "    model_path = save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )\n",
    "    # Save grid search results ---\n",
    "    save_grid(model_path=model_path, search=search, **saver_grid_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53356a01-d3c8-459e-80e7-a2b7c3eec8f2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0159fd90-d2c3-4f60-9c80-c7b8fd667149",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### BASELINE MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7bf43b-5d3a-4624-8b19-f7fd6a459d0f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid_search_kwargs = dict(\n",
    "    scoring=\"neg_mean_absolute_error\", n_jobs=cpus_to_use, refit=True, cv=skf, verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ac80fa-5401-4541-a2ba-2870ee955369",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "saver_params = dict(\n",
    "    dataset=dataset,\n",
    "    model_name=\"mlp\",\n",
    "    objective=\"mae\",\n",
    "    toScale=toScale,\n",
    "    init_time=init_time,\n",
    "    columns_used=all_cols,\n",
    "    Preprocess=Preprocess,\n",
    "    preprocessing_path=scaler_name,\n",
    "    categorical=categorical,\n",
    ")\n",
    "\n",
    "# --- --- --- BASELINE MLP --- --- ---\n",
    "if toFitMLP:\n",
    "    model, kind, best_score = fit_baseline_model(\n",
    "        train_mlp_classification,\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        pass_val=False,\n",
    "        params=None,\n",
    "    )\n",
    "\n",
    "    scores_df = get_results(model, data_splits)\n",
    "    # SAVE RESULTS ------\n",
    "    save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3a44aa-bbd7-4245-9315-48b81c607cc6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### GRID SEARCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b06762-141c-48f6-abb2-7d89fc1e96ef",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# --- --- --- SVM GRID SEARCH --- --- ---\n",
    "if toFitMLP:\n",
    "    kind = \"grid\"\n",
    "\n",
    "    search = fit_grid_model(\n",
    "        train_mlp_classification,\n",
    "        data=[(X_train, y_train), (X_validation, y_validation)],\n",
    "        grid_params=mlp_params,\n",
    "        grid_search_kwargs=grid_search_kwargs,\n",
    "        pass_val=False,\n",
    "        params=None,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "    # REFIT TO GET TRAINING ERROR AT EACH STEP ------\n",
    "    model = search.best_estimator_\n",
    "    # Score model ---\n",
    "    scores_df = get_results(model, data_splits)\n",
    "    best_score = search.best_score_\n",
    "    # Save model ---\n",
    "    model_path = save_model(\n",
    "        model=model, kind=kind, best_score=best_score, scores=scores_df, **saver_params\n",
    "    )\n",
    "    # Save grid search results ---\n",
    "    save_grid(model_path=model_path, search=search, **saver_grid_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee426434-3f7c-4088-81dd-861643127a0b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## END "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f22c09b-4b50-4819-9dad-ffc200e71b7d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PRINT EXECUTION TIME ------\n",
    "e = datetime.now()  # end time\n",
    "delta = e - s  # timedelta\n",
    "# extract ---\n",
    "days = delta.days\n",
    "seconds = delta.seconds\n",
    "# calcultate hours, minutes\n",
    "hours = seconds // 3600\n",
    "minutes = (seconds // 60) % 60\n",
    "print(\"------ EXECUTION TIME ------\")\n",
    "print(\"days:\", days, \"hours:\", hours, \"minutes:\", minutes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 6.967648,
   "end_time": "2022-02-06T21:07:13.566074",
   "environment_variables": {},
   "exception": true,
   "input_path": "/home/jovyan/work/TP3_TP4/trainers/cat_trainer.ipynb",
   "output_path": "/home/jovyan/work/TP3_TP4/Jupyter Outputs/bill_trained.ipynb",
   "parameters": {
    "categorical": false,
    "dataset": "bill",
    "dependent": "Class",
    "to_rm_storage": false,
    "training_data_path": "wine_train"
   },
   "start_time": "2022-02-06T21:07:06.598426",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}